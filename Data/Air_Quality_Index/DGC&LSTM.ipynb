{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('AQI_finaldataset.csv')\n",
    "df = df.drop(['Location','CO','NO','NH3','O3'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 - 4s - loss: 0.1048 - val_loss: 0.0829 - 4s/epoch - 238ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0615 - val_loss: 0.0596 - 407ms/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0498 - val_loss: 0.0602 - 387ms/epoch - 22ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0446 - val_loss: 0.0555 - 395ms/epoch - 22ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0387 - val_loss: 0.0514 - 475ms/epoch - 26ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0366 - val_loss: 0.0540 - 395ms/epoch - 22ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0340 - val_loss: 0.0539 - 393ms/epoch - 22ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0323 - val_loss: 0.0520 - 388ms/epoch - 22ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0291 - val_loss: 0.0526 - 384ms/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0294 - val_loss: 0.0541 - 379ms/epoch - 21ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0292 - val_loss: 0.0530 - 391ms/epoch - 22ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0290 - val_loss: 0.0492 - 392ms/epoch - 22ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0273 - val_loss: 0.0471 - 405ms/epoch - 22ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0270 - val_loss: 0.0501 - 387ms/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0260 - val_loss: 0.0421 - 391ms/epoch - 22ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0244 - val_loss: 0.0444 - 377ms/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0228 - val_loss: 0.0406 - 382ms/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0232 - val_loss: 0.0409 - 385ms/epoch - 21ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0234 - val_loss: 0.0377 - 420ms/epoch - 23ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0228 - val_loss: 0.0404 - 388ms/epoch - 22ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0210 - val_loss: 0.0391 - 383ms/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0220 - val_loss: 0.0322 - 381ms/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0199 - val_loss: 0.0346 - 384ms/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0204 - val_loss: 0.0304 - 381ms/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0193 - val_loss: 0.0303 - 393ms/epoch - 22ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0190 - val_loss: 0.0293 - 388ms/epoch - 22ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0190 - val_loss: 0.0279 - 383ms/epoch - 21ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0192 - val_loss: 0.0252 - 391ms/epoch - 22ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0175 - val_loss: 0.0236 - 386ms/epoch - 21ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0183 - val_loss: 0.0238 - 382ms/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0189 - val_loss: 0.0242 - 387ms/epoch - 22ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0169 - val_loss: 0.0247 - 378ms/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0187 - val_loss: 0.0236 - 396ms/epoch - 22ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0169 - val_loss: 0.0236 - 387ms/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0167 - val_loss: 0.0231 - 390ms/epoch - 22ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0163 - val_loss: 0.0213 - 383ms/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0154 - val_loss: 0.0219 - 412ms/epoch - 23ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0161 - val_loss: 0.0220 - 389ms/epoch - 22ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0217 - 382ms/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0150 - val_loss: 0.0257 - 385ms/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0158 - val_loss: 0.0228 - 378ms/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0146 - val_loss: 0.0218 - 380ms/epoch - 21ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0245 - 403ms/epoch - 22ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0140 - val_loss: 0.0219 - 384ms/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0155 - val_loss: 0.0233 - 378ms/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0141 - val_loss: 0.0237 - 441ms/epoch - 24ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0141 - val_loss: 0.0216 - 378ms/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0213 - 384ms/epoch - 21ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0223 - 379ms/epoch - 21ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0133 - val_loss: 0.0216 - 380ms/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0218 - 390ms/epoch - 22ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0134 - val_loss: 0.0237 - 388ms/epoch - 22ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0204 - 383ms/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0218 - 388ms/epoch - 22ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0129 - val_loss: 0.0228 - 401ms/epoch - 22ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0227 - 382ms/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0215 - 394ms/epoch - 22ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0211 - 378ms/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0222 - 379ms/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0230 - 387ms/epoch - 22ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0213 - 384ms/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0115 - val_loss: 0.0219 - 380ms/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0216 - 379ms/epoch - 21ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0217 - 383ms/epoch - 21ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0213 - 391ms/epoch - 22ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0216 - 391ms/epoch - 22ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0222 - 392ms/epoch - 22ms/step\n",
      "Epoch 68/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0211 - 399ms/epoch - 22ms/step\n",
      "Epoch 69/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0206 - 386ms/epoch - 21ms/step\n",
      "Epoch 70/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0215 - 395ms/epoch - 22ms/step\n",
      "Epoch 71/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0212 - 379ms/epoch - 21ms/step\n",
      "Epoch 72/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0204 - 379ms/epoch - 21ms/step\n",
      "Epoch 73/100\n",
      "18/18 - 0s - loss: 0.0111 - val_loss: 0.0211 - 380ms/epoch - 21ms/step\n",
      "Epoch 73: early stopping\n",
      "5/5 [==============================] - 1s 8ms/step\n",
      "Test RMSE: 65.931\n",
      "[143.55284    8.75015   10.023126  81.67581   71.28319 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "# Load data\n",
    "\n",
    "df=pd.read_csv('AQI_finaldataset.csv')\n",
    "df = df.drop(['Location','CO','NO','NH3','O3'],axis=1)\n",
    "\n",
    "# Filter data for a given location\n",
    "location_id =0\n",
    "df = df[df[\"Location_ID\"] == location_id]\n",
    "\n",
    "# Convert date column to datetime format\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Sort data by date\n",
    "df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "# Extract target variables\n",
    "targets = [\"AQI\", \"NO2\", \"SO2\", \"PM10\", \"PM2.5\"]\n",
    "y = df[targets]\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# Define sequence length for LSTM\n",
    "seq_length = 30\n",
    "\n",
    "# Create input and output sequences\n",
    "X, Y = [], []\n",
    "for i in range(len(y_scaled) - seq_length):\n",
    "    X.append(y_scaled[i:i+seq_length])\n",
    "    Y.append(y_scaled[i+seq_length])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define model architecture\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define input layer\n",
    "inputs = Input(shape=(seq_length, len(targets)))\n",
    "\n",
    "# Define spatial graph convolution layer\n",
    "for i in range (3):\n",
    "    graph_conv = Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "    graph_conv = MaxPooling1D(pool_size=2)(graph_conv)\n",
    "    graph_conv = BatchNormalization()(graph_conv)\n",
    "\n",
    "    # Define temporal graph convolution layer\n",
    "    temp_conv = Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "    temp_conv = MaxPooling1D(pool_size=2)(temp_conv)\n",
    "    temp_conv = BatchNormalization()(temp_conv)\n",
    "\n",
    "# Concatenate graph convolutions\n",
    "    merged = Concatenate( axis=-1 )([graph_conv, temp_conv])\n",
    "\n",
    "    # Define LSTM layer\n",
    "lstm = LSTM(128)(merged)\n",
    "\n",
    "\n",
    "# Define dense layers\n",
    "\n",
    "dense = Dense(64, activation='relu')(lstm)\n",
    "dense = Dropout(0.5)(dense)\n",
    "dense = Dense(len(targets))(dense)\n",
    "dense = Dense(64, activation='relu')(lstm)\n",
    "dense = Dropout(0.5)(dense)\n",
    "dense = Dense(len(targets))(dense)\n",
    "\n",
    "# Define output layer\n",
    "outputs = dense\n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "# model.summary()\n",
    "\n",
    "# Train model\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test,y_test), callbacks=[es], verbose=2)\n",
    "# history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test,y_test), verbose=2)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Calculate root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(y_pred[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define future date range\n",
    "start_date = '2023-02-01'\n",
    "end_date = '2023-02-28'\n",
    "freq = 'D'\n",
    "future_dates = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "\n",
    "# Create input sequences for future dates\n",
    "last_seq = np.array(X_test[-1])  # last sequence from the test data\n",
    "input_seq = last_seq.copy()\n",
    "preds = []\n",
    "for i in range(len(future_dates)):\n",
    "    pred = model.predict(input_seq.reshape(1, seq_length, len(targets)))\n",
    "    preds.append(pred)\n",
    "    input_seq = np.append(input_seq[1:], pred, axis=0)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "preds = np.array(preds).reshape(-1, len(targets))\n",
    "preds_inv = scaler.inverse_transform(preds)\n",
    "\n",
    "# Convert predictions and dates to a pandas DataFrame\n",
    "preds_df = pd.DataFrame(preds_inv, index=future_dates, columns=targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
