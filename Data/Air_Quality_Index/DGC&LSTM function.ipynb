{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('AQI_finaldataset.csv')\n",
    "df = df.drop(['Location','CO','NO','NH3','O3'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>155</td>\n",
       "      <td>11.532500</td>\n",
       "      <td>14.119167</td>\n",
       "      <td>64.316667</td>\n",
       "      <td>71.244583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>175</td>\n",
       "      <td>17.677500</td>\n",
       "      <td>7.001667</td>\n",
       "      <td>101.994167</td>\n",
       "      <td>115.704583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>160</td>\n",
       "      <td>6.395833</td>\n",
       "      <td>3.274583</td>\n",
       "      <td>75.047500</td>\n",
       "      <td>81.250833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>160</td>\n",
       "      <td>9.455417</td>\n",
       "      <td>10.259167</td>\n",
       "      <td>74.220000</td>\n",
       "      <td>87.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>168</td>\n",
       "      <td>15.177917</td>\n",
       "      <td>6.458333</td>\n",
       "      <td>88.811250</td>\n",
       "      <td>98.957917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>157</td>\n",
       "      <td>24.267500</td>\n",
       "      <td>19.873750</td>\n",
       "      <td>68.129583</td>\n",
       "      <td>76.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>166</td>\n",
       "      <td>27.073750</td>\n",
       "      <td>14.355833</td>\n",
       "      <td>86.390000</td>\n",
       "      <td>99.132917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>143</td>\n",
       "      <td>3.838333</td>\n",
       "      <td>2.935000</td>\n",
       "      <td>52.775417</td>\n",
       "      <td>58.132917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>166</td>\n",
       "      <td>8.980833</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>85.993333</td>\n",
       "      <td>98.587083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>156</td>\n",
       "      <td>9.577500</td>\n",
       "      <td>3.736667</td>\n",
       "      <td>66.760833</td>\n",
       "      <td>74.665833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3695 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location_ID        Date  AQI        NO2        SO2       PM2.5  \\\n",
       "0               0  2020-01-12  155  11.532500  14.119167   64.316667   \n",
       "1               1  2020-01-12  175  17.677500   7.001667  101.994167   \n",
       "2               2  2020-01-12  160   6.395833   3.274583   75.047500   \n",
       "3               3  2020-01-12  160   9.455417  10.259167   74.220000   \n",
       "4               4  2020-01-12  168  15.177917   6.458333   88.811250   \n",
       "...           ...         ...  ...        ...        ...         ...   \n",
       "3690            0  2022-12-30  157  24.267500  19.873750   68.129583   \n",
       "3691            1  2022-12-30  166  27.073750  14.355833   86.390000   \n",
       "3692            2  2022-12-30  143   3.838333   2.935000   52.775417   \n",
       "3693            3  2022-12-30  166   8.980833  12.270000   85.993333   \n",
       "3694            4  2022-12-30  156   9.577500   3.736667   66.760833   \n",
       "\n",
       "            PM10  \n",
       "0      71.244583  \n",
       "1     115.704583  \n",
       "2      81.250833  \n",
       "3      87.468750  \n",
       "4      98.957917  \n",
       "...          ...  \n",
       "3690   76.675000  \n",
       "3691   99.132917  \n",
       "3692   58.132917  \n",
       "3693   98.587083  \n",
       "3694   74.665833  \n",
       "\n",
       "[3695 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on test data\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Calculate root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dgc_lstm_model(df, location_id, model_name):\n",
    "    # Filter data by location\n",
    "    df = df[df[\"Location_ID\"] == location_id]\n",
    "\n",
    "    # Convert date column to datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Sort data by date\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "    # Extract target variables\n",
    "    targets = [\"AQI\", \"NO2\", \"SO2\", \"PM10\", \"PM2.5\"]\n",
    "    y = df[targets]\n",
    "\n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "    # Define sequence length for LSTM\n",
    "    seq_length = 30\n",
    "\n",
    "    # Create input and output sequences\n",
    "    X, Y = [], []\n",
    "    for i in range(len(y_scaled) - seq_length):\n",
    "        X.append(y_scaled[i:i+seq_length])\n",
    "        Y.append(y_scaled[i+seq_length])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=(seq_length, len(targets)))\n",
    "\n",
    "    # Define spatial graph convolution layer\n",
    "    for i in range(3):\n",
    "        graph_conv = Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "        graph_conv = MaxPooling1D(pool_size=2)(graph_conv)\n",
    "        graph_conv = BatchNormalization()(graph_conv)\n",
    "\n",
    "        # Define temporal graph convolution layer\n",
    "        temp_conv = Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "        temp_conv = MaxPooling1D(pool_size=2)(temp_conv)\n",
    "        temp_conv = BatchNormalization()(temp_conv)\n",
    "\n",
    "        # Concatenate graph convolutions\n",
    "        merged = Concatenate(axis=-1)([graph_conv, temp_conv])\n",
    "\n",
    "    # Define LSTM layer\n",
    "    lstm = LSTM(128)(merged)\n",
    "\n",
    "    # Define dense layers\n",
    "    dense = Dense(64, activation='relu')(lstm)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(len(targets))(dense)\n",
    "    dense = Dense(64, activation='relu')(lstm)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(len(targets))(dense)\n",
    "\n",
    "    # Define output layer\n",
    "    outputs = dense\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    # Train model\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), callbacks=[es], verbose=2)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/1885808831.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:30:01.848900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:30:02.177042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:30:02.269221: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 2s - loss: 0.0996 - val_loss: 0.0883 - 2s/epoch - 113ms/step\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:30:02.954121: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:30:03.037964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - loss: 0.0606 - val_loss: 0.0798 - 326ms/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0485 - val_loss: 0.0759 - 320ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0459 - val_loss: 0.0690 - 325ms/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0411 - val_loss: 0.0673 - 312ms/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0400 - val_loss: 0.0622 - 317ms/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0366 - val_loss: 0.0654 - 323ms/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0341 - val_loss: 0.0579 - 315ms/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0323 - val_loss: 0.0592 - 314ms/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0321 - val_loss: 0.0525 - 303ms/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0307 - val_loss: 0.0504 - 297ms/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0278 - val_loss: 0.0467 - 326ms/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0276 - val_loss: 0.0484 - 291ms/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0285 - val_loss: 0.0486 - 308ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0262 - val_loss: 0.0439 - 307ms/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0265 - val_loss: 0.0438 - 347ms/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0240 - val_loss: 0.0434 - 338ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0256 - val_loss: 0.0397 - 288ms/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0249 - val_loss: 0.0379 - 288ms/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0244 - val_loss: 0.0409 - 307ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0246 - val_loss: 0.0415 - 311ms/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0247 - val_loss: 0.0395 - 301ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0222 - val_loss: 0.0368 - 311ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0226 - val_loss: 0.0330 - 308ms/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0217 - val_loss: 0.0333 - 311ms/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0214 - val_loss: 0.0323 - 300ms/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0201 - val_loss: 0.0351 - 303ms/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0197 - val_loss: 0.0350 - 314ms/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0312 - 310ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0176 - val_loss: 0.0301 - 311ms/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0178 - val_loss: 0.0340 - 307ms/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0192 - val_loss: 0.0315 - 293ms/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0203 - val_loss: 0.0338 - 309ms/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0185 - val_loss: 0.0359 - 325ms/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0180 - val_loss: 0.0345 - 307ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0372 - 315ms/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0358 - 304ms/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0175 - val_loss: 0.0301 - 316ms/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0170 - val_loss: 0.0320 - 307ms/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0158 - val_loss: 0.0296 - 326ms/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0295 - 310ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0151 - val_loss: 0.0331 - 323ms/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0150 - val_loss: 0.0369 - 381ms/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0162 - val_loss: 0.0408 - 395ms/epoch - 22ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0402 - 308ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0358 - 299ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0343 - 301ms/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0142 - val_loss: 0.0318 - 341ms/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0331 - 301ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0326 - 302ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0131 - val_loss: 0.0297 - 287ms/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0141 - val_loss: 0.0298 - 332ms/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0140 - val_loss: 0.0261 - 316ms/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0271 - 305ms/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0273 - 302ms/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0297 - 297ms/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0309 - 304ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0134 - val_loss: 0.0377 - 297ms/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0416 - 294ms/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0133 - val_loss: 0.0375 - 297ms/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0408 - 293ms/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0338 - 306ms/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0334 - 300ms/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0129 - val_loss: 0.0301 - 325ms/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0300 - 333ms/epoch - 18ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0317 - 309ms/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0307 - 301ms/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "18/18 - 0s - loss: 0.0115 - val_loss: 0.0292 - 304ms/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0258 - 307ms/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0271 - 316ms/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0260 - 335ms/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0295 - 298ms/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0277 - 305ms/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0279 - 308ms/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "18/18 - 0s - loss: 0.0115 - val_loss: 0.0281 - 330ms/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0307 - 316ms/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "18/18 - 0s - loss: 0.0108 - val_loss: 0.0274 - 310ms/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "18/18 - 0s - loss: 0.0106 - val_loss: 0.0262 - 338ms/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0283 - 321ms/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0310 - 315ms/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0254 - 320ms/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0253 - 320ms/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0267 - 325ms/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0257 - 302ms/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0251 - 300ms/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0275 - 294ms/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0285 - 325ms/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0275 - 308ms/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "18/18 - 0s - loss: 0.0099 - val_loss: 0.0256 - 306ms/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0273 - 314ms/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "18/18 - 0s - loss: 0.0111 - val_loss: 0.0289 - 308ms/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0252 - 322ms/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0293 - 314ms/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0272 - 333ms/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "18/18 - 0s - loss: 0.0097 - val_loss: 0.0275 - 327ms/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "18/18 - 0s - loss: 0.0093 - val_loss: 0.0269 - 335ms/epoch - 19ms/step\n",
      "Epoch 97/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0277 - 316ms/epoch - 18ms/step\n",
      "Epoch 98/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0265 - 313ms/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "18/18 - 0s - loss: 0.0094 - val_loss: 0.0269 - 309ms/epoch - 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "18/18 - 0s - loss: 0.0093 - val_loss: 0.0279 - 309ms/epoch - 17ms/step\n"
     ]
    }
   ],
   "source": [
    "model_a1 = train_dgc_lstm_model(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, X_test, scaler, seq_length, targets, start_date, end_date, freq='D'):\n",
    "    \"\"\"\n",
    "    Generates predictions for future dates using a trained LSTM model.\n",
    "\n",
    "    Args:\n",
    "    - model: a trained Keras LSTM model\n",
    "    - X_test: a numpy array of shape (num_samples, seq_length, num_features) containing test data\n",
    "    - scaler: a fitted sklearn.preprocessing.MinMaxScaler object used to scale the data\n",
    "    - seq_length: the sequence length used for training the model\n",
    "    - targets: a list of target column names\n",
    "    - start_date: the start date for the future date range (string in 'YYYY-MM-DD' format)\n",
    "    - end_date: the end date for the future date range (string in 'YYYY-MM-DD' format)\n",
    "    - freq: the frequency of the future date range (default='D')\n",
    "\n",
    "    Returns:\n",
    "    - preds_df: a pandas DataFrame of shape (num_predictions, num_targets) containing the predicted values\n",
    "    \"\"\"\n",
    "    # Define future date range\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "\n",
    "    # Create input sequences for future dates\n",
    "    last_seq = np.array(X_test[-1])  # last sequence from the test data\n",
    "    input_seq = last_seq.copy()\n",
    "    preds = []\n",
    "    for i in range(len(future_dates)):\n",
    "        pred = model.predict(input_seq.reshape(1, seq_length, len(targets)))\n",
    "        preds.append(pred)\n",
    "        input_seq = np.append(input_seq[1:], pred, axis=0)\n",
    "\n",
    "    # Inverse transform the predicted values\n",
    "    preds = np.array(preds).reshape(-1, len(targets))\n",
    "    preds_inv = scaler.inverse_transform(preds)\n",
    "\n",
    "    # Convert predictions and dates to a pandas DataFrame\n",
    "    preds_df = pd.DataFrame(preds_inv, index=future_dates, columns=targets)\n",
    "\n",
    "    return preds_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:31:07.794324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:31:07.898232: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>162.523788</td>\n",
       "      <td>11.167418</td>\n",
       "      <td>14.255235</td>\n",
       "      <td>93.550308</td>\n",
       "      <td>81.979271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-02</th>\n",
       "      <td>148.921844</td>\n",
       "      <td>9.537496</td>\n",
       "      <td>12.976024</td>\n",
       "      <td>84.865593</td>\n",
       "      <td>74.539513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03</th>\n",
       "      <td>152.632736</td>\n",
       "      <td>9.872520</td>\n",
       "      <td>11.704534</td>\n",
       "      <td>82.854492</td>\n",
       "      <td>71.401192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-04</th>\n",
       "      <td>180.298477</td>\n",
       "      <td>11.798573</td>\n",
       "      <td>14.726301</td>\n",
       "      <td>106.969116</td>\n",
       "      <td>93.979752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-05</th>\n",
       "      <td>170.798859</td>\n",
       "      <td>11.148227</td>\n",
       "      <td>13.152823</td>\n",
       "      <td>101.216438</td>\n",
       "      <td>88.853577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06</th>\n",
       "      <td>152.787964</td>\n",
       "      <td>11.065556</td>\n",
       "      <td>13.720207</td>\n",
       "      <td>90.383537</td>\n",
       "      <td>80.171448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>162.080917</td>\n",
       "      <td>10.013520</td>\n",
       "      <td>13.988982</td>\n",
       "      <td>91.313484</td>\n",
       "      <td>80.437233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>186.766342</td>\n",
       "      <td>10.476390</td>\n",
       "      <td>16.331343</td>\n",
       "      <td>108.023811</td>\n",
       "      <td>94.844765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>180.666489</td>\n",
       "      <td>10.571139</td>\n",
       "      <td>15.781747</td>\n",
       "      <td>102.292770</td>\n",
       "      <td>89.433189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>170.329193</td>\n",
       "      <td>10.640274</td>\n",
       "      <td>15.417902</td>\n",
       "      <td>97.506882</td>\n",
       "      <td>85.453720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-11</th>\n",
       "      <td>167.879532</td>\n",
       "      <td>9.710434</td>\n",
       "      <td>14.502666</td>\n",
       "      <td>92.298775</td>\n",
       "      <td>80.296844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-12</th>\n",
       "      <td>189.620697</td>\n",
       "      <td>10.767115</td>\n",
       "      <td>16.049006</td>\n",
       "      <td>108.547554</td>\n",
       "      <td>94.347214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>184.512314</td>\n",
       "      <td>10.541819</td>\n",
       "      <td>14.618626</td>\n",
       "      <td>103.246925</td>\n",
       "      <td>89.315735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14</th>\n",
       "      <td>159.222992</td>\n",
       "      <td>9.942591</td>\n",
       "      <td>13.165209</td>\n",
       "      <td>86.114487</td>\n",
       "      <td>74.071663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15</th>\n",
       "      <td>160.245148</td>\n",
       "      <td>9.620550</td>\n",
       "      <td>12.606546</td>\n",
       "      <td>84.550453</td>\n",
       "      <td>72.154495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-16</th>\n",
       "      <td>175.514313</td>\n",
       "      <td>10.174840</td>\n",
       "      <td>13.843532</td>\n",
       "      <td>95.806602</td>\n",
       "      <td>81.809868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17</th>\n",
       "      <td>169.855652</td>\n",
       "      <td>10.171059</td>\n",
       "      <td>13.030133</td>\n",
       "      <td>94.043701</td>\n",
       "      <td>80.956810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-18</th>\n",
       "      <td>164.922653</td>\n",
       "      <td>10.676130</td>\n",
       "      <td>12.863521</td>\n",
       "      <td>95.639496</td>\n",
       "      <td>83.027382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-19</th>\n",
       "      <td>171.853012</td>\n",
       "      <td>10.952326</td>\n",
       "      <td>13.778387</td>\n",
       "      <td>99.275780</td>\n",
       "      <td>85.688560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-20</th>\n",
       "      <td>182.864395</td>\n",
       "      <td>11.161283</td>\n",
       "      <td>14.687943</td>\n",
       "      <td>106.206924</td>\n",
       "      <td>91.505981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-21</th>\n",
       "      <td>177.064270</td>\n",
       "      <td>10.600306</td>\n",
       "      <td>14.002193</td>\n",
       "      <td>99.539391</td>\n",
       "      <td>85.243095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-22</th>\n",
       "      <td>175.897263</td>\n",
       "      <td>10.351958</td>\n",
       "      <td>14.269053</td>\n",
       "      <td>97.879936</td>\n",
       "      <td>83.587021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-23</th>\n",
       "      <td>167.907394</td>\n",
       "      <td>9.656161</td>\n",
       "      <td>13.686399</td>\n",
       "      <td>89.574730</td>\n",
       "      <td>76.083832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24</th>\n",
       "      <td>181.463470</td>\n",
       "      <td>10.678943</td>\n",
       "      <td>15.068107</td>\n",
       "      <td>99.990929</td>\n",
       "      <td>84.949570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-25</th>\n",
       "      <td>176.721085</td>\n",
       "      <td>10.649586</td>\n",
       "      <td>14.494112</td>\n",
       "      <td>97.915077</td>\n",
       "      <td>83.547508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26</th>\n",
       "      <td>165.182388</td>\n",
       "      <td>10.422557</td>\n",
       "      <td>13.653762</td>\n",
       "      <td>91.293198</td>\n",
       "      <td>78.074127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27</th>\n",
       "      <td>167.960297</td>\n",
       "      <td>10.204235</td>\n",
       "      <td>13.328257</td>\n",
       "      <td>91.826416</td>\n",
       "      <td>78.315033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>179.255859</td>\n",
       "      <td>10.609464</td>\n",
       "      <td>14.142268</td>\n",
       "      <td>100.585869</td>\n",
       "      <td>86.052765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AQI        NO2        SO2        PM10      PM2.5\n",
       "2023-02-01  162.523788  11.167418  14.255235   93.550308  81.979271\n",
       "2023-02-02  148.921844   9.537496  12.976024   84.865593  74.539513\n",
       "2023-02-03  152.632736   9.872520  11.704534   82.854492  71.401192\n",
       "2023-02-04  180.298477  11.798573  14.726301  106.969116  93.979752\n",
       "2023-02-05  170.798859  11.148227  13.152823  101.216438  88.853577\n",
       "2023-02-06  152.787964  11.065556  13.720207   90.383537  80.171448\n",
       "2023-02-07  162.080917  10.013520  13.988982   91.313484  80.437233\n",
       "2023-02-08  186.766342  10.476390  16.331343  108.023811  94.844765\n",
       "2023-02-09  180.666489  10.571139  15.781747  102.292770  89.433189\n",
       "2023-02-10  170.329193  10.640274  15.417902   97.506882  85.453720\n",
       "2023-02-11  167.879532   9.710434  14.502666   92.298775  80.296844\n",
       "2023-02-12  189.620697  10.767115  16.049006  108.547554  94.347214\n",
       "2023-02-13  184.512314  10.541819  14.618626  103.246925  89.315735\n",
       "2023-02-14  159.222992   9.942591  13.165209   86.114487  74.071663\n",
       "2023-02-15  160.245148   9.620550  12.606546   84.550453  72.154495\n",
       "2023-02-16  175.514313  10.174840  13.843532   95.806602  81.809868\n",
       "2023-02-17  169.855652  10.171059  13.030133   94.043701  80.956810\n",
       "2023-02-18  164.922653  10.676130  12.863521   95.639496  83.027382\n",
       "2023-02-19  171.853012  10.952326  13.778387   99.275780  85.688560\n",
       "2023-02-20  182.864395  11.161283  14.687943  106.206924  91.505981\n",
       "2023-02-21  177.064270  10.600306  14.002193   99.539391  85.243095\n",
       "2023-02-22  175.897263  10.351958  14.269053   97.879936  83.587021\n",
       "2023-02-23  167.907394   9.656161  13.686399   89.574730  76.083832\n",
       "2023-02-24  181.463470  10.678943  15.068107   99.990929  84.949570\n",
       "2023-02-25  176.721085  10.649586  14.494112   97.915077  83.547508\n",
       "2023-02-26  165.182388  10.422557  13.653762   91.293198  78.074127\n",
       "2023-02-27  167.960297  10.204235  13.328257   91.826416  78.315033\n",
       "2023-02-28  179.255859  10.609464  14.142268  100.585869  86.052765"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_future(model_a1, X_test, scaler, seq_length, targets, start_date='2023-02-01', end_date='2023-02-28', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/1885808831.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:37:04.509641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.010126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.104594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.884573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.974438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 2s - loss: 0.0871 - val_loss: 0.0569 - 2s/epoch - 135ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0501 - val_loss: 0.0503 - 340ms/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0384 - val_loss: 0.0487 - 324ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0351 - val_loss: 0.0441 - 312ms/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0340 - val_loss: 0.0455 - 327ms/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0322 - val_loss: 0.0519 - 303ms/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0305 - val_loss: 0.0452 - 325ms/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0286 - val_loss: 0.0471 - 343ms/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0267 - val_loss: 0.0431 - 334ms/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0257 - val_loss: 0.0403 - 327ms/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0231 - val_loss: 0.0396 - 300ms/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0232 - val_loss: 0.0418 - 338ms/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0239 - val_loss: 0.0407 - 299ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0212 - val_loss: 0.0371 - 306ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0211 - val_loss: 0.0371 - 301ms/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0217 - val_loss: 0.0346 - 326ms/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0207 - val_loss: 0.0323 - 333ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0196 - val_loss: 0.0374 - 337ms/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0191 - val_loss: 0.0358 - 316ms/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0168 - val_loss: 0.0327 - 309ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0172 - val_loss: 0.0344 - 339ms/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0167 - val_loss: 0.0317 - 325ms/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0175 - val_loss: 0.0307 - 302ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0172 - val_loss: 0.0310 - 317ms/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0155 - val_loss: 0.0275 - 303ms/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0159 - val_loss: 0.0272 - 305ms/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0160 - val_loss: 0.0268 - 296ms/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0159 - val_loss: 0.0274 - 315ms/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0154 - val_loss: 0.0249 - 298ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0155 - val_loss: 0.0254 - 291ms/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0143 - val_loss: 0.0277 - 324ms/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0149 - val_loss: 0.0251 - 297ms/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0240 - 313ms/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0252 - 312ms/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0138 - val_loss: 0.0271 - 302ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0288 - 297ms/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0245 - 296ms/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0242 - 327ms/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0237 - 292ms/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0132 - val_loss: 0.0268 - 298ms/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0323 - 310ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0122 - val_loss: 0.0247 - 306ms/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0296 - 325ms/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0133 - val_loss: 0.0233 - 323ms/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0222 - 310ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0226 - 306ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0249 - 339ms/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0223 - 283ms/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0122 - val_loss: 0.0244 - 315ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0248 - 341ms/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0274 - 306ms/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0238 - 291ms/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0239 - 327ms/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0245 - 335ms/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0128 - val_loss: 0.0260 - 329ms/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0111 - val_loss: 0.0248 - 303ms/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0252 - 315ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0245 - 320ms/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0235 - 330ms/epoch - 18ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0234 - 304ms/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0240 - 292ms/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0105 - val_loss: 0.0264 - 313ms/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0253 - 346ms/epoch - 19ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0243 - 304ms/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0095 - val_loss: 0.0253 - 351ms/epoch - 19ms/step\n",
      "Epoch 65: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_a0 = train_dgc_lstm_model(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:37:50.462930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:50.596795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>162.771133</td>\n",
       "      <td>8.578809</td>\n",
       "      <td>10.257969</td>\n",
       "      <td>74.333763</td>\n",
       "      <td>65.543640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-02</th>\n",
       "      <td>155.618668</td>\n",
       "      <td>9.642659</td>\n",
       "      <td>10.749367</td>\n",
       "      <td>65.164429</td>\n",
       "      <td>58.346062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03</th>\n",
       "      <td>137.193817</td>\n",
       "      <td>10.482187</td>\n",
       "      <td>10.591032</td>\n",
       "      <td>66.760521</td>\n",
       "      <td>60.936653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-04</th>\n",
       "      <td>148.329849</td>\n",
       "      <td>9.368301</td>\n",
       "      <td>9.232942</td>\n",
       "      <td>65.932884</td>\n",
       "      <td>56.474411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-05</th>\n",
       "      <td>162.153366</td>\n",
       "      <td>12.445340</td>\n",
       "      <td>13.331022</td>\n",
       "      <td>84.649017</td>\n",
       "      <td>74.881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06</th>\n",
       "      <td>165.553268</td>\n",
       "      <td>11.889607</td>\n",
       "      <td>12.774716</td>\n",
       "      <td>86.200409</td>\n",
       "      <td>75.430260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>181.898666</td>\n",
       "      <td>13.350243</td>\n",
       "      <td>15.209957</td>\n",
       "      <td>104.040871</td>\n",
       "      <td>91.545937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>191.209564</td>\n",
       "      <td>10.657102</td>\n",
       "      <td>12.977812</td>\n",
       "      <td>97.556847</td>\n",
       "      <td>81.120544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>198.160217</td>\n",
       "      <td>11.220460</td>\n",
       "      <td>13.994368</td>\n",
       "      <td>98.291000</td>\n",
       "      <td>81.231293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>196.761093</td>\n",
       "      <td>9.032623</td>\n",
       "      <td>11.634832</td>\n",
       "      <td>88.886742</td>\n",
       "      <td>69.486313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-11</th>\n",
       "      <td>208.225677</td>\n",
       "      <td>10.490720</td>\n",
       "      <td>13.548796</td>\n",
       "      <td>99.889824</td>\n",
       "      <td>79.141953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-12</th>\n",
       "      <td>190.273300</td>\n",
       "      <td>9.291825</td>\n",
       "      <td>11.432539</td>\n",
       "      <td>87.235283</td>\n",
       "      <td>65.229828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>186.621338</td>\n",
       "      <td>11.175428</td>\n",
       "      <td>13.070667</td>\n",
       "      <td>93.143364</td>\n",
       "      <td>73.343445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14</th>\n",
       "      <td>178.882721</td>\n",
       "      <td>10.152822</td>\n",
       "      <td>11.581899</td>\n",
       "      <td>84.456848</td>\n",
       "      <td>63.832241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15</th>\n",
       "      <td>187.000977</td>\n",
       "      <td>10.362572</td>\n",
       "      <td>12.143617</td>\n",
       "      <td>89.924461</td>\n",
       "      <td>68.058578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-16</th>\n",
       "      <td>184.692215</td>\n",
       "      <td>10.710979</td>\n",
       "      <td>12.256781</td>\n",
       "      <td>88.811188</td>\n",
       "      <td>67.511047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17</th>\n",
       "      <td>185.523697</td>\n",
       "      <td>10.271967</td>\n",
       "      <td>11.966063</td>\n",
       "      <td>89.990372</td>\n",
       "      <td>67.723412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-18</th>\n",
       "      <td>182.993393</td>\n",
       "      <td>10.392121</td>\n",
       "      <td>12.004256</td>\n",
       "      <td>90.311455</td>\n",
       "      <td>68.707077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-19</th>\n",
       "      <td>194.465134</td>\n",
       "      <td>10.559232</td>\n",
       "      <td>12.738009</td>\n",
       "      <td>96.866722</td>\n",
       "      <td>73.668747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-20</th>\n",
       "      <td>193.575378</td>\n",
       "      <td>10.294939</td>\n",
       "      <td>12.468082</td>\n",
       "      <td>96.060532</td>\n",
       "      <td>72.832115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-21</th>\n",
       "      <td>199.844116</td>\n",
       "      <td>10.297045</td>\n",
       "      <td>12.825958</td>\n",
       "      <td>98.022995</td>\n",
       "      <td>73.986191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-22</th>\n",
       "      <td>198.680237</td>\n",
       "      <td>9.486366</td>\n",
       "      <td>11.961335</td>\n",
       "      <td>94.081612</td>\n",
       "      <td>69.578209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-23</th>\n",
       "      <td>201.805771</td>\n",
       "      <td>9.920100</td>\n",
       "      <td>12.433014</td>\n",
       "      <td>95.374207</td>\n",
       "      <td>70.369370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24</th>\n",
       "      <td>192.146805</td>\n",
       "      <td>9.126615</td>\n",
       "      <td>11.425615</td>\n",
       "      <td>88.791389</td>\n",
       "      <td>64.561165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-25</th>\n",
       "      <td>191.242950</td>\n",
       "      <td>9.591578</td>\n",
       "      <td>11.804286</td>\n",
       "      <td>89.208031</td>\n",
       "      <td>65.571892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26</th>\n",
       "      <td>187.911926</td>\n",
       "      <td>9.166576</td>\n",
       "      <td>11.331486</td>\n",
       "      <td>86.675568</td>\n",
       "      <td>63.201927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27</th>\n",
       "      <td>186.261963</td>\n",
       "      <td>9.053236</td>\n",
       "      <td>11.142272</td>\n",
       "      <td>85.812317</td>\n",
       "      <td>62.713703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>186.022430</td>\n",
       "      <td>9.608478</td>\n",
       "      <td>11.679623</td>\n",
       "      <td>88.501999</td>\n",
       "      <td>65.765137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AQI        NO2        SO2        PM10      PM2.5\n",
       "2023-02-01  162.771133   8.578809  10.257969   74.333763  65.543640\n",
       "2023-02-02  155.618668   9.642659  10.749367   65.164429  58.346062\n",
       "2023-02-03  137.193817  10.482187  10.591032   66.760521  60.936653\n",
       "2023-02-04  148.329849   9.368301   9.232942   65.932884  56.474411\n",
       "2023-02-05  162.153366  12.445340  13.331022   84.649017  74.881264\n",
       "2023-02-06  165.553268  11.889607  12.774716   86.200409  75.430260\n",
       "2023-02-07  181.898666  13.350243  15.209957  104.040871  91.545937\n",
       "2023-02-08  191.209564  10.657102  12.977812   97.556847  81.120544\n",
       "2023-02-09  198.160217  11.220460  13.994368   98.291000  81.231293\n",
       "2023-02-10  196.761093   9.032623  11.634832   88.886742  69.486313\n",
       "2023-02-11  208.225677  10.490720  13.548796   99.889824  79.141953\n",
       "2023-02-12  190.273300   9.291825  11.432539   87.235283  65.229828\n",
       "2023-02-13  186.621338  11.175428  13.070667   93.143364  73.343445\n",
       "2023-02-14  178.882721  10.152822  11.581899   84.456848  63.832241\n",
       "2023-02-15  187.000977  10.362572  12.143617   89.924461  68.058578\n",
       "2023-02-16  184.692215  10.710979  12.256781   88.811188  67.511047\n",
       "2023-02-17  185.523697  10.271967  11.966063   89.990372  67.723412\n",
       "2023-02-18  182.993393  10.392121  12.004256   90.311455  68.707077\n",
       "2023-02-19  194.465134  10.559232  12.738009   96.866722  73.668747\n",
       "2023-02-20  193.575378  10.294939  12.468082   96.060532  72.832115\n",
       "2023-02-21  199.844116  10.297045  12.825958   98.022995  73.986191\n",
       "2023-02-22  198.680237   9.486366  11.961335   94.081612  69.578209\n",
       "2023-02-23  201.805771   9.920100  12.433014   95.374207  70.369370\n",
       "2023-02-24  192.146805   9.126615  11.425615   88.791389  64.561165\n",
       "2023-02-25  191.242950   9.591578  11.804286   89.208031  65.571892\n",
       "2023-02-26  187.911926   9.166576  11.331486   86.675568  63.201927\n",
       "2023-02-27  186.261963   9.053236  11.142272   85.812317  62.713703\n",
       "2023-02-28  186.022430   9.608478  11.679623   88.501999  65.765137"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_future(model_a0, X_test, scaler, seq_length, targets, start_date='2023-02-01', end_date='2023-02-28', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_map = {'Adilabad': 0, \n",
    "                'Karimnagar': 1, \n",
    "                'Khammam': 2, \n",
    "                'Nizamabad': 3, \n",
    "                'Warangal': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/929710441.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 21:27:39.176607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:27:40.414085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:27:40.557543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:27:41.509253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:27:41.621023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 7s - loss: 0.0871 - val_loss: 0.0690 - 7s/epoch - 395ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0471 - val_loss: 0.0682 - 368ms/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0384 - val_loss: 0.0657 - 317ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0338 - val_loss: 0.0610 - 322ms/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0302 - val_loss: 0.0560 - 324ms/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0285 - val_loss: 0.0586 - 309ms/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0293 - val_loss: 0.0567 - 300ms/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0264 - val_loss: 0.0541 - 318ms/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0247 - val_loss: 0.0541 - 310ms/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0235 - val_loss: 0.0546 - 315ms/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0224 - val_loss: 0.0508 - 359ms/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0223 - val_loss: 0.0518 - 306ms/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0219 - val_loss: 0.0527 - 319ms/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0214 - val_loss: 0.0499 - 293ms/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0210 - val_loss: 0.0454 - 298ms/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0201 - val_loss: 0.0402 - 333ms/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0203 - val_loss: 0.0379 - 318ms/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0181 - val_loss: 0.0387 - 341ms/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0190 - val_loss: 0.0391 - 322ms/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0170 - val_loss: 0.0386 - 295ms/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0186 - val_loss: 0.0350 - 302ms/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0185 - val_loss: 0.0363 - 312ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0371 - 300ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0166 - val_loss: 0.0328 - 298ms/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0162 - val_loss: 0.0332 - 305ms/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0157 - val_loss: 0.0317 - 295ms/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0150 - val_loss: 0.0293 - 313ms/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0150 - val_loss: 0.0282 - 314ms/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0148 - val_loss: 0.0271 - 322ms/epoch - 18ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0146 - val_loss: 0.0268 - 288ms/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0142 - val_loss: 0.0282 - 302ms/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0141 - val_loss: 0.0269 - 306ms/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0252 - 323ms/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0272 - 318ms/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0315 - 299ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0295 - 326ms/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0245 - 303ms/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0135 - val_loss: 0.0257 - 305ms/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0129 - val_loss: 0.0258 - 293ms/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0280 - 308ms/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0245 - 314ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0233 - 306ms/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0238 - 311ms/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0237 - 306ms/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0129 - val_loss: 0.0246 - 319ms/epoch - 18ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0244 - 308ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0252 - 314ms/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0267 - 310ms/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0126 - val_loss: 0.0271 - 328ms/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0274 - 345ms/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0259 - 328ms/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0278 - 347ms/epoch - 19ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0108 - val_loss: 0.0268 - 386ms/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0269 - 326ms/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0252 - 371ms/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0257 - 316ms/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0107 - val_loss: 0.0253 - 331ms/epoch - 18ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0106 - val_loss: 0.0235 - 358ms/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0247 - 334ms/epoch - 19ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0257 - 354ms/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0250 - 412ms/epoch - 23ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0237 - 388ms/epoch - 22ms/step\n",
      "Epoch 62: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/929710441.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 21:28:03.053553: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:03.573031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:03.695034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:05.252624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:05.411696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 4s - loss: 0.0937 - val_loss: 0.0851 - 4s/epoch - 198ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0554 - val_loss: 0.0849 - 455ms/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0482 - val_loss: 0.0727 - 447ms/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0435 - val_loss: 0.0665 - 384ms/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0393 - val_loss: 0.0638 - 351ms/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0360 - val_loss: 0.0671 - 339ms/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0358 - val_loss: 0.0719 - 412ms/epoch - 23ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0362 - val_loss: 0.0604 - 327ms/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0317 - val_loss: 0.0561 - 454ms/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0308 - val_loss: 0.0514 - 419ms/epoch - 23ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 1s - loss: 0.0275 - val_loss: 0.0487 - 531ms/epoch - 29ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 1s - loss: 0.0267 - val_loss: 0.0491 - 1s/epoch - 65ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0277 - val_loss: 0.0493 - 351ms/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0265 - val_loss: 0.0503 - 337ms/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0250 - val_loss: 0.0472 - 333ms/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0248 - val_loss: 0.0468 - 335ms/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0238 - val_loss: 0.0453 - 339ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0247 - val_loss: 0.0472 - 349ms/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0239 - val_loss: 0.0447 - 319ms/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0223 - val_loss: 0.0425 - 337ms/epoch - 19ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0213 - val_loss: 0.0401 - 385ms/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0214 - val_loss: 0.0387 - 333ms/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0204 - val_loss: 0.0363 - 385ms/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0187 - val_loss: 0.0371 - 332ms/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0184 - val_loss: 0.0388 - 350ms/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0198 - val_loss: 0.0372 - 354ms/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0178 - val_loss: 0.0347 - 405ms/epoch - 22ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0165 - val_loss: 0.0370 - 351ms/epoch - 20ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0178 - val_loss: 0.0338 - 368ms/epoch - 20ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0169 - val_loss: 0.0333 - 369ms/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0166 - val_loss: 0.0312 - 327ms/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0170 - val_loss: 0.0315 - 362ms/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0313 - 333ms/epoch - 19ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0159 - val_loss: 0.0344 - 336ms/epoch - 19ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0142 - val_loss: 0.0327 - 346ms/epoch - 19ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0153 - val_loss: 0.0322 - 379ms/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0146 - val_loss: 0.0340 - 374ms/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0321 - 364ms/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0338 - 369ms/epoch - 20ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0148 - val_loss: 0.0346 - 327ms/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0325 - 306ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0314 - 321ms/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0157 - val_loss: 0.0317 - 327ms/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0162 - val_loss: 0.0315 - 319ms/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0142 - val_loss: 0.0329 - 334ms/epoch - 19ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0158 - val_loss: 0.0327 - 328ms/epoch - 18ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0138 - val_loss: 0.0304 - 308ms/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0132 - val_loss: 0.0336 - 334ms/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0135 - val_loss: 0.0315 - 305ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0129 - val_loss: 0.0307 - 335ms/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0126 - val_loss: 0.0312 - 300ms/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0318 - 329ms/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0134 - val_loss: 0.0303 - 315ms/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0296 - 339ms/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0314 - 346ms/epoch - 19ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0306 - 311ms/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0323 - 305ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0327 - 309ms/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0310 - 315ms/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0107 - val_loss: 0.0301 - 322ms/epoch - 18ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0106 - val_loss: 0.0315 - 311ms/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0322 - 304ms/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0105 - val_loss: 0.0335 - 359ms/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0105 - val_loss: 0.0315 - 315ms/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0326 - 305ms/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 0.0100 - val_loss: 0.0340 - 308ms/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0321 - 318ms/epoch - 18ms/step\n",
      "Epoch 68/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0325 - 311ms/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0301 - 310ms/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "18/18 - 0s - loss: 0.0099 - val_loss: 0.0299 - 316ms/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0299 - 298ms/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "18/18 - 0s - loss: 0.0093 - val_loss: 0.0316 - 303ms/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "18/18 - 0s - loss: 0.0106 - val_loss: 0.0320 - 296ms/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0306 - 313ms/epoch - 17ms/step\n",
      "Epoch 74: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/929710441.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 21:28:33.992801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:34.500493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:34.635774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:35.499735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:35.614885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 3s - loss: 0.0703 - val_loss: 0.0676 - 3s/epoch - 142ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0404 - val_loss: 0.0588 - 398ms/epoch - 22ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0344 - val_loss: 0.0575 - 301ms/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0303 - val_loss: 0.0507 - 347ms/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0299 - val_loss: 0.0505 - 325ms/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0280 - val_loss: 0.0483 - 309ms/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0269 - val_loss: 0.0433 - 306ms/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0253 - val_loss: 0.0457 - 318ms/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0245 - val_loss: 0.0423 - 330ms/epoch - 18ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0245 - val_loss: 0.0387 - 307ms/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0210 - val_loss: 0.0427 - 325ms/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0209 - val_loss: 0.0351 - 300ms/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0205 - val_loss: 0.0331 - 304ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0209 - val_loss: 0.0334 - 335ms/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0192 - val_loss: 0.0338 - 322ms/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0184 - val_loss: 0.0344 - 315ms/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0178 - val_loss: 0.0341 - 316ms/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0184 - val_loss: 0.0356 - 333ms/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0173 - val_loss: 0.0312 - 303ms/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0174 - val_loss: 0.0307 - 303ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0169 - val_loss: 0.0277 - 307ms/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0261 - 291ms/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0251 - 304ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0163 - val_loss: 0.0289 - 305ms/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0154 - val_loss: 0.0271 - 330ms/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0148 - val_loss: 0.0270 - 299ms/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0141 - val_loss: 0.0256 - 307ms/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0267 - 329ms/epoch - 18ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0154 - val_loss: 0.0263 - 311ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0154 - val_loss: 0.0253 - 294ms/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0143 - val_loss: 0.0256 - 317ms/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0146 - val_loss: 0.0271 - 300ms/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0142 - val_loss: 0.0238 - 331ms/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0131 - val_loss: 0.0258 - 318ms/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0140 - val_loss: 0.0237 - 287ms/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0134 - val_loss: 0.0223 - 291ms/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0126 - val_loss: 0.0224 - 311ms/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0135 - val_loss: 0.0226 - 329ms/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0132 - val_loss: 0.0233 - 323ms/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0227 - 303ms/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0225 - 307ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0223 - 310ms/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0227 - 310ms/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0251 - 294ms/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0257 - 314ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0244 - 314ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0280 - 336ms/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0282 - 302ms/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0111 - val_loss: 0.0268 - 311ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0260 - 305ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0241 - 331ms/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0247 - 320ms/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0239 - 298ms/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0107 - val_loss: 0.0226 - 307ms/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0243 - 308ms/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0098 - val_loss: 0.0237 - 328ms/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0248 - 309ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0105 - val_loss: 0.0241 - 319ms/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0246 - 307ms/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0098 - val_loss: 0.0249 - 308ms/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0098 - val_loss: 0.0242 - 299ms/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0098 - val_loss: 0.0229 - 304ms/epoch - 17ms/step\n",
      "Epoch 62: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/929710441.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 21:28:55.895147: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:56.275861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:56.364242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:57.163811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:28:57.281021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 2s - loss: 0.0981 - val_loss: 0.0967 - 2s/epoch - 125ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0570 - val_loss: 0.0730 - 358ms/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0442 - val_loss: 0.0670 - 324ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0396 - val_loss: 0.0674 - 335ms/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0379 - val_loss: 0.0615 - 314ms/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0368 - val_loss: 0.0633 - 323ms/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0320 - val_loss: 0.0653 - 304ms/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0305 - val_loss: 0.0596 - 289ms/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0283 - val_loss: 0.0575 - 306ms/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0282 - val_loss: 0.0544 - 342ms/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0262 - val_loss: 0.0514 - 289ms/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0243 - val_loss: 0.0529 - 296ms/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0249 - val_loss: 0.0528 - 288ms/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0232 - val_loss: 0.0503 - 296ms/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0232 - val_loss: 0.0482 - 278ms/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0216 - val_loss: 0.0480 - 293ms/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0217 - val_loss: 0.0468 - 339ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0207 - val_loss: 0.0395 - 304ms/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0202 - val_loss: 0.0407 - 291ms/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0184 - val_loss: 0.0366 - 306ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0199 - val_loss: 0.0361 - 318ms/epoch - 18ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0207 - val_loss: 0.0406 - 300ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0195 - val_loss: 0.0379 - 323ms/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0181 - val_loss: 0.0358 - 306ms/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0175 - val_loss: 0.0349 - 292ms/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0310 - 326ms/epoch - 18ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0319 - 306ms/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0306 - 335ms/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0180 - val_loss: 0.0314 - 302ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0167 - val_loss: 0.0276 - 346ms/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0156 - val_loss: 0.0260 - 304ms/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0156 - val_loss: 0.0268 - 305ms/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0262 - 319ms/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0245 - 310ms/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0247 - 310ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0253 - 322ms/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0146 - val_loss: 0.0249 - 310ms/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0155 - val_loss: 0.0309 - 308ms/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0153 - val_loss: 0.0265 - 307ms/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0269 - 315ms/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0148 - val_loss: 0.0262 - 304ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0263 - 333ms/epoch - 19ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0157 - val_loss: 0.0372 - 311ms/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0143 - val_loss: 0.0310 - 309ms/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0294 - 312ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0149 - val_loss: 0.0299 - 306ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0138 - val_loss: 0.0306 - 308ms/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0135 - val_loss: 0.0278 - 315ms/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0262 - 311ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0135 - val_loss: 0.0269 - 305ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0133 - val_loss: 0.0258 - 321ms/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0313 - 304ms/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0327 - 306ms/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0301 - 307ms/epoch - 17ms/step\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/929710441.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 21:29:15.456924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:29:15.861776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:29:15.965082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:29:16.853456: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 21:29:16.962109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 3s - loss: 0.0831 - val_loss: 0.0724 - 3s/epoch - 160ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0485 - val_loss: 0.0617 - 401ms/epoch - 22ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0386 - val_loss: 0.0572 - 322ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0350 - val_loss: 0.0534 - 320ms/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0323 - val_loss: 0.0591 - 310ms/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0342 - val_loss: 0.0583 - 306ms/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0303 - val_loss: 0.0538 - 310ms/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0296 - val_loss: 0.0476 - 330ms/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0275 - val_loss: 0.0470 - 309ms/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0274 - val_loss: 0.0432 - 310ms/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0254 - val_loss: 0.0397 - 292ms/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0261 - val_loss: 0.0431 - 312ms/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0238 - val_loss: 0.0443 - 303ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0229 - val_loss: 0.0383 - 307ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0214 - val_loss: 0.0376 - 368ms/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0218 - val_loss: 0.0396 - 320ms/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0214 - val_loss: 0.0407 - 306ms/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0209 - val_loss: 0.0387 - 305ms/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0203 - val_loss: 0.0367 - 322ms/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0200 - val_loss: 0.0385 - 308ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0196 - val_loss: 0.0381 - 310ms/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0197 - val_loss: 0.0356 - 308ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0195 - val_loss: 0.0325 - 306ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0188 - val_loss: 0.0352 - 302ms/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0171 - val_loss: 0.0356 - 298ms/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0297 - 299ms/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0161 - val_loss: 0.0287 - 314ms/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0169 - val_loss: 0.0302 - 304ms/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0162 - val_loss: 0.0275 - 309ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0163 - val_loss: 0.0270 - 314ms/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0151 - val_loss: 0.0254 - 303ms/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0264 - 299ms/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0260 - 306ms/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0146 - val_loss: 0.0255 - 310ms/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0246 - 301ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0253 - 311ms/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0249 - 315ms/epoch - 18ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0140 - val_loss: 0.0256 - 303ms/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0265 - 309ms/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0131 - val_loss: 0.0251 - 306ms/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0123 - val_loss: 0.0260 - 309ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0128 - val_loss: 0.0268 - 302ms/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0131 - val_loss: 0.0267 - 337ms/epoch - 19ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0126 - val_loss: 0.0275 - 305ms/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0254 - 309ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0265 - 309ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0244 - 306ms/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0246 - 322ms/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0253 - 310ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0256 - 309ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0271 - 303ms/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0248 - 309ms/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0267 - 347ms/epoch - 19ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0261 - 299ms/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0245 - 308ms/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0108 - val_loss: 0.0262 - 295ms/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0108 - val_loss: 0.0271 - 306ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0106 - val_loss: 0.0268 - 306ms/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0259 - 452ms/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 1s - loss: 0.0098 - val_loss: 0.0269 - 903ms/epoch - 50ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0275 - 333ms/epoch - 18ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0105 - val_loss: 0.0277 - 323ms/epoch - 18ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0274 - 324ms/epoch - 18ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0266 - 325ms/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0099 - val_loss: 0.0257 - 336ms/epoch - 19ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 0.0097 - val_loss: 0.0254 - 348ms/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0255 - 344ms/epoch - 19ms/step\n",
      "Epoch 67: early stopping\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "# Train models for each location\n",
    "for location, location_id in location_map.items():\n",
    "    model_name = f'model_{location}'\n",
    "    models[location] = train_dgc_lstm_model(df, location_id, model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adilabad': 'model_Adilabad',\n",
       " 'Karimnagar': 'model_Karimnagar',\n",
       " 'Khammam': 'model_Khammam',\n",
       " 'Nizamabad': 'model_Nizamabad',\n",
       " 'Warangal': 'model_Warangal'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for location, location_id in location_map.items():\n",
    "    model_name = f'model_{location}'\n",
    "    models[location] = model_name\n",
    "    \n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adilabad\n",
      "                   AQI        NO2        SO2        PM10      PM2.5\n",
      "2023-02-01  145.585464  10.634912  11.447943   70.385742  61.724670\n",
      "2023-02-02  142.335953  13.639072  13.685410   73.008522  71.411621\n",
      "2023-02-03  153.112946  14.382212  14.045220   89.532478  81.721413\n",
      "2023-02-04  140.909576  10.707196   9.811964   72.778259  65.019577\n",
      "2023-02-05  141.576721  12.909809  13.336891   92.796135  86.440262\n",
      "2023-02-06  151.155014  12.439368  13.014493   90.489906  82.493477\n",
      "2023-02-07  162.420776  14.107489  14.952380   99.974678  93.190308\n",
      "2023-02-08  169.944534  14.274529  16.027988  101.956329  94.628090\n",
      "2023-02-09  168.333145  14.453926  16.159643   96.249832  89.529640\n",
      "2023-02-10  174.442520  15.369645  17.698011   99.094559  90.749382\n",
      "2023-02-11  172.343124  15.140398  16.940590   91.985481  84.594307\n",
      "2023-02-12  173.700378  16.792500  19.455008   97.554932  88.698997\n",
      "2023-02-13  169.686493  16.904932  18.662216   92.634834  85.101128\n",
      "2023-02-14  166.764999  17.899858  20.676622   95.532761  86.210808\n",
      "2023-02-15  160.395782  17.350531  19.418764   90.400986  81.582962\n",
      "2023-02-16  155.777435  17.343372  20.156672   91.421715  80.213440\n",
      "2023-02-17  152.728363  16.270168  18.538181   86.540649  76.410950\n",
      "2023-02-18  152.772888  15.578176  18.096493   90.350357  77.769501\n",
      "2023-02-19  154.154678  14.799122  17.268164   88.402771  76.725304\n",
      "2023-02-20  154.064041  14.424249  16.906635   90.697525  76.811081\n",
      "2023-02-21  157.114914  14.336998  17.305748   88.085220  74.411102\n",
      "2023-02-22  163.067230  14.789897  18.073702   93.335266  78.979813\n",
      "2023-02-23  163.140442  15.675923  19.178070   88.122269  75.438774\n",
      "2023-02-24  163.228882  16.193127  19.654858   87.623108  75.491959\n",
      "2023-02-25  156.257324  16.152092  19.391973   80.728195  68.509422\n",
      "2023-02-26  150.846558  15.684745  18.846937   77.974930  66.123009\n",
      "2023-02-27  140.614349  14.805211  17.688509   72.854874  58.482964\n",
      "2023-02-28  138.743332  14.065994  17.195612   76.178108  57.776566\n",
      "Karimnagar\n",
      "                   AQI        NO2        SO2        PM10       PM2.5\n",
      "2023-02-01  160.516129   8.759826  10.452461   82.427765   79.038101\n",
      "2023-02-02  156.127594   7.902865  11.102407   74.459442   73.308052\n",
      "2023-02-03  154.208923   9.715127  10.456488   86.947838   83.599342\n",
      "2023-02-04  167.514969  10.116837  10.858259   97.675484   93.246025\n",
      "2023-02-05  180.829346  12.598620  14.236164  113.260796  106.652527\n",
      "2023-02-06  192.751923  14.031017  16.294859  127.512482  119.709099\n",
      "2023-02-07  168.776627  12.658356  14.734394  105.786621   97.334946\n",
      "2023-02-08  157.353699  10.863834  13.108880   90.508415   84.105705\n",
      "2023-02-09  158.423813   9.325473  12.861179   80.546356   73.966057\n",
      "2023-02-10  164.861115   8.805611  12.358436   83.875145   77.981461\n",
      "2023-02-11  166.856964   9.217441  13.168179   84.334267   79.183823\n",
      "2023-02-12  161.084015  10.627871  13.111405   87.005493   81.659309\n",
      "2023-02-13  174.279068  12.660409  14.530863  104.246124   96.996689\n",
      "2023-02-14  177.630692  13.787847  14.499119  112.366241  102.928093\n",
      "2023-02-15  169.579987  12.208763  14.095031  100.713432   91.719398\n",
      "2023-02-16  167.709061  10.977342  13.661279   93.393883   85.854149\n",
      "2023-02-17  164.646042   8.654458  12.413013   79.650307   74.132378\n",
      "2023-02-18  172.717484   9.339924  13.517755   87.108505   81.473915\n",
      "2023-02-19  169.314056   8.444438  12.538718   79.449516   75.113564\n",
      "2023-02-20  164.431091   9.962507  12.981232   86.796432   81.290344\n",
      "2023-02-21  165.573273  10.636003  12.545615   93.769783   87.125420\n",
      "2023-02-22  172.100708  11.861443  13.092049  103.714882   95.580070\n",
      "2023-02-23  179.760712  13.111922  14.001394  111.549782  102.432808\n",
      "2023-02-24  177.470413  12.324862  14.578590  104.292290   96.129753\n",
      "2023-02-25  166.139755  10.388843  13.546430   88.005753   81.288216\n",
      "2023-02-26  164.930130   9.271929  12.953279   80.208061   74.928802\n",
      "2023-02-27  168.054977   8.253262  12.449498   75.854507   71.136803\n",
      "2023-02-28  172.909973   9.130419  13.447344   83.104858   78.936111\n",
      "Khammam\n",
      "                   AQI        NO2        SO2       PM10      PM2.5\n",
      "2023-02-01   82.373962   8.729265   9.203576  34.048618  27.674730\n",
      "2023-02-02   76.240028   8.784635  10.084893  27.766781  21.210363\n",
      "2023-02-03   83.801231  13.301673  13.772609  34.628056  26.934425\n",
      "2023-02-04   69.453011   9.597968   8.632539  25.994566  19.988462\n",
      "2023-02-05  108.483223  12.092699  14.502567  47.717777  42.346535\n",
      "2023-02-06   81.606186   8.551024   7.427783  32.585846  27.030680\n",
      "2023-02-07  101.928391   8.080617   9.810379  45.364498  33.993423\n",
      "2023-02-08  125.537598   9.001216   9.941905  59.835678  49.574436\n",
      "2023-02-09  121.470764   9.223824  12.777445  58.903515  42.581585\n",
      "2023-02-10  117.467979  10.105700  13.446929  54.387573  40.526009\n",
      "2023-02-11  115.196541  10.027697  12.840889  57.639225  44.205311\n",
      "2023-02-12  119.493988   9.901348  13.169827  62.928688  47.152897\n",
      "2023-02-13  128.022476   9.769599  13.850324  72.063698  53.294907\n",
      "2023-02-14  120.329437   8.809982  12.214536  68.323166  49.134365\n",
      "2023-02-15  121.982674   8.298330  11.844294  70.898430  50.896793\n",
      "2023-02-16  107.592140   7.752857  10.169035  59.381451  40.969757\n",
      "2023-02-17  100.934914   7.940482   9.501395  55.749874  35.321865\n",
      "2023-02-18   93.307053   7.764985   8.639338  47.851917  30.097546\n",
      "2023-02-19   87.876877   8.360172   7.710853  43.631687  28.954767\n",
      "2023-02-20   89.992302   9.012996   7.765960  44.249363  33.126278\n",
      "2023-02-21   95.087624   9.917771   8.444809  46.745319  39.047321\n",
      "2023-02-22  106.371178  10.618135  10.489263  51.535702  45.307255\n",
      "2023-02-23  116.193970  11.132442  11.541874  58.652241  51.341099\n",
      "2023-02-24  115.799217  10.513336  11.874546  60.708027  48.577335\n",
      "2023-02-25  113.771332   9.711136  11.430631  63.889641  48.099255\n",
      "2023-02-26  105.752617   8.814402  10.662146  59.152359  42.907806\n",
      "2023-02-27  106.094498   7.967568   9.968013  61.826759  43.192738\n",
      "2023-02-28  101.646622   6.836578   9.049697  61.086777  40.674782\n",
      "Nizamabad\n",
      "                   AQI        NO2        SO2        PM10       PM2.5\n",
      "2023-02-01  153.398697   9.156159  10.806527   81.333076   68.669792\n",
      "2023-02-02  157.480255   8.701417  11.442966   85.430862   71.158157\n",
      "2023-02-03  153.926849   9.698046  11.490529   85.658424   72.004784\n",
      "2023-02-04  156.809799   9.276751  11.557240   85.768471   72.656387\n",
      "2023-02-05  154.577332  10.174750  11.804704   87.335480   75.823380\n",
      "2023-02-06  169.157532  10.393924  12.723005   97.630898   84.715950\n",
      "2023-02-07  180.924393  11.189135  13.943915  108.061714   94.759888\n",
      "2023-02-08  196.369125  11.442244  15.100809  119.426765  104.096237\n",
      "2023-02-09  198.126144  11.710625  15.414086  121.579437  106.126816\n",
      "2023-02-10  196.743195  11.554127  15.247041  120.500336  104.809883\n",
      "2023-02-11  191.039429  11.574722  14.821854  117.194321  101.984924\n",
      "2023-02-12  182.206253  11.371613  14.120034  110.842941   96.374496\n",
      "2023-02-13  174.381622  11.221040  13.495516  105.051765   91.437653\n",
      "2023-02-14  167.692230  11.066962  12.960670  100.189919   87.381508\n",
      "2023-02-15  163.428101  10.978252  12.664762   97.063629   84.904472\n",
      "2023-02-16  160.261124  10.959927  12.469407   95.127800   83.448433\n",
      "2023-02-17  160.958054  11.131847  12.825034   95.905701   82.868225\n",
      "2023-02-18  162.435837  11.228847  13.174004   97.345940   82.651176\n",
      "2023-02-19  165.455688  11.422751  13.681174  100.288925   83.913696\n",
      "2023-02-20  167.439056  11.573361  13.885952  102.884193   85.302933\n",
      "2023-02-21  168.216553  11.666013  13.978034  104.415947   86.047195\n",
      "2023-02-22  169.139603  11.752864  14.036486  105.605309   86.917435\n",
      "2023-02-23  169.073547  11.714902  14.034449  105.556076   86.862450\n",
      "2023-02-24  167.678604  11.617900  13.909200  104.400261   85.738823\n",
      "2023-02-25  165.258820  11.456505  13.707595  102.351875   83.813805\n",
      "2023-02-26  161.962479  11.288820  13.414490   99.807060   81.245438\n",
      "2023-02-27  159.161575  11.170838  13.197693   97.700844   79.063568\n",
      "2023-02-28  155.861023  11.059905  12.947898   95.349266   76.325607\n",
      "Warangal\n",
      "                   AQI        NO2        SO2        PM10      PM2.5\n",
      "2023-02-01  121.025383  10.247442   9.857194   59.997234  52.726662\n",
      "2023-02-02  130.690659  10.356598   9.997024   62.469646  52.459522\n",
      "2023-02-03  111.087959  10.591702   9.044806   51.943336  46.472462\n",
      "2023-02-04  121.846031  13.927874  13.146235   65.934616  58.614330\n",
      "2023-02-05  129.904587  13.533052  12.206965   63.249619  50.415249\n",
      "2023-02-06  147.609924  16.553940  14.693674   81.502388  63.893280\n",
      "2023-02-07  169.700241  15.098322  17.066969   99.162025  85.723122\n",
      "2023-02-08  161.679016  15.441994  15.911705   97.769005  82.213348\n",
      "2023-02-09  170.952606  14.214728  16.124290  110.114273  93.838226\n",
      "2023-02-10  161.566132  13.232341  15.079997   97.371971  83.035629\n",
      "2023-02-11  181.933777  12.256853  16.787182  113.078468  99.099968\n",
      "2023-02-12  159.317307  11.619623  14.945960   95.300423  83.497475\n",
      "2023-02-13  157.582123  11.530281  15.462582   94.404152  82.161194\n",
      "2023-02-14  127.318138  10.972011  12.361245   69.679985  59.813286\n",
      "2023-02-15  133.310806  10.242652  13.398542   75.025948  61.980064\n",
      "2023-02-16  127.085114  10.296801  11.682397   67.970444  56.503479\n",
      "2023-02-17  118.530388   9.299396  11.089897   63.152344  52.880791\n",
      "2023-02-18  134.166626  10.119386  11.959423   77.133888  63.055141\n",
      "2023-02-19  138.376450   9.208335  12.580711   82.937935  67.463417\n",
      "2023-02-20  143.655823  11.513126  13.132813   88.793854  71.384911\n",
      "2023-02-21  146.988297  12.208586  13.044035   87.878784  75.094482\n",
      "2023-02-22  147.044617  12.916802  12.981729   87.477798  73.694550\n",
      "2023-02-23  148.906403  12.873801  13.273774   88.701645  73.504097\n",
      "2023-02-24  159.432175  12.729170  14.267931   94.830772  77.671783\n",
      "2023-02-25  159.678391  12.355992  14.632434   95.441628  77.949211\n",
      "2023-02-26  160.624466  12.349337  14.990869   98.111755  80.184036\n",
      "2023-02-27  153.652618  11.868612  14.644316   93.494881  76.131462\n",
      "2023-02-28  156.114426  11.633420  14.900508   95.250015  78.263809\n"
     ]
    }
   ],
   "source": [
    "for loc,model in models.items():\n",
    "    print(loc)\n",
    "    forecast = predict_future(model, X_test, scaler, seq_length, targets, start_date='2023-02-01', end_date='2023-02-28', freq='D')\n",
    "    print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
