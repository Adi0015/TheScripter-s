{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"AQI_finaldataset.csv\")\n",
    "df = df.drop(['Location','CO','NO','O3','NH3'], axis=1)\n",
    "# df = df.set_index('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>0</td>\n",
       "      <td>11.532500</td>\n",
       "      <td>14.119167</td>\n",
       "      <td>64.316667</td>\n",
       "      <td>71.244583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-12</th>\n",
       "      <td>0</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>26.246667</td>\n",
       "      <td>101.804167</td>\n",
       "      <td>110.420417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-12</th>\n",
       "      <td>0</td>\n",
       "      <td>15.100833</td>\n",
       "      <td>22.189167</td>\n",
       "      <td>110.429167</td>\n",
       "      <td>119.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-12</th>\n",
       "      <td>0</td>\n",
       "      <td>14.997083</td>\n",
       "      <td>24.111667</td>\n",
       "      <td>106.747500</td>\n",
       "      <td>115.307083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>0</td>\n",
       "      <td>11.063750</td>\n",
       "      <td>16.193333</td>\n",
       "      <td>81.322917</td>\n",
       "      <td>88.081667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>0</td>\n",
       "      <td>6.898333</td>\n",
       "      <td>1.936111</td>\n",
       "      <td>26.607222</td>\n",
       "      <td>29.861667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>9.137917</td>\n",
       "      <td>2.842917</td>\n",
       "      <td>25.796250</td>\n",
       "      <td>29.078750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>9.494167</td>\n",
       "      <td>8.117500</td>\n",
       "      <td>51.737083</td>\n",
       "      <td>57.072917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0</td>\n",
       "      <td>11.177083</td>\n",
       "      <td>14.606250</td>\n",
       "      <td>82.650417</td>\n",
       "      <td>89.879167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>24.267500</td>\n",
       "      <td>19.873750</td>\n",
       "      <td>68.129583</td>\n",
       "      <td>76.675000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Location_ID        NO2        SO2       PM2.5        PM10\n",
       "Date                                                                 \n",
       "2020-01-12            0  11.532500  14.119167   64.316667   71.244583\n",
       "2020-02-12            0  14.900000  26.246667  101.804167  110.420417\n",
       "2020-03-12            0  15.100833  22.189167  110.429167  119.453333\n",
       "2020-04-12            0  14.997083  24.111667  106.747500  115.307083\n",
       "2020-05-12            0  11.063750  16.193333   81.322917   88.081667\n",
       "...                 ...        ...        ...         ...         ...\n",
       "2022-12-26            0   6.898333   1.936111   26.607222   29.861667\n",
       "2022-12-27            0   9.137917   2.842917   25.796250   29.078750\n",
       "2022-12-28            0   9.494167   8.117500   51.737083   57.072917\n",
       "2022-12-29            0  11.177083  14.606250   82.650417   89.879167\n",
       "2022-12-30            0  24.267500  19.873750   68.129583   76.675000\n",
       "\n",
       "[739 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 2s 30ms/step - loss: 19152.1367 - val_loss: 15136.7197\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 18418.2188 - val_loss: 13830.4873\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 17184.7539 - val_loss: 11922.8076\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 15295.5059 - val_loss: 10256.9102\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12746.4443 - val_loss: 9642.2256\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9896.2041 - val_loss: 9769.2637\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7249.9111 - val_loss: 8735.3125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5423.5444 - val_loss: 7240.1182\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 4829.0205 - val_loss: 6391.7876\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 4033.4695 - val_loss: 5390.1748\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3668.0859 - val_loss: 5481.2261\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3425.4629 - val_loss: 5543.9468\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3267.2798 - val_loss: 7042.1240\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3220.7256 - val_loss: 5552.7964\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2903.7119 - val_loss: 6274.5918\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2837.3496 - val_loss: 7309.6099\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2783.5869 - val_loss: 6732.7549\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2821.1785 - val_loss: 5292.4009\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2679.2998 - val_loss: 5854.8418\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2296.5198 - val_loss: 5565.3965\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2228.0396 - val_loss: 5816.0557\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2232.3853 - val_loss: 5213.1069\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2301.3252 - val_loss: 4672.6646\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2019.8345 - val_loss: 4965.9971\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1989.7538 - val_loss: 4993.2524\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2000.1788 - val_loss: 4676.2935\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2023.4938 - val_loss: 4806.8193\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1972.2257 - val_loss: 4917.4487\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1972.3796 - val_loss: 5157.9932\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1783.5972 - val_loss: 5230.1519\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1856.5867 - val_loss: 4675.5884\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1711.8158 - val_loss: 4569.6050\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1741.8026 - val_loss: 3540.1033\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1648.6234 - val_loss: 3644.7285\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1478.5665 - val_loss: 4048.9463\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1513.7161 - val_loss: 3657.4250\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1507.6523 - val_loss: 3944.4744\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1527.8141 - val_loss: 4191.9663\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1505.7136 - val_loss: 5095.0425\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1538.7399 - val_loss: 4429.9189\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1465.8302 - val_loss: 4784.9058\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1370.6281 - val_loss: 4899.6768\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1362.8542 - val_loss: 5006.4658\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1377.5157 - val_loss: 4278.2148\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1369.2072 - val_loss: 3739.3838\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1359.8088 - val_loss: 3724.2122\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1313.7828 - val_loss: 4033.9507\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1300.8596 - val_loss: 4203.9453\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1273.1113 - val_loss: 3629.8086\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1213.2208 - val_loss: 3792.5906\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1315.2809 - val_loss: 4331.4756\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1187.9846 - val_loss: 4452.3193\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1132.3542 - val_loss: 5413.2847\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1166.5699 - val_loss: 4442.6880\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1157.5397 - val_loss: 4998.2358\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1117.0405 - val_loss: 4787.5820\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1109.2815 - val_loss: 5423.3506\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1128.2351 - val_loss: 3748.7825\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1094.2649 - val_loss: 3696.5613\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1084.7471 - val_loss: 5163.9395\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1151.3167 - val_loss: 4247.2881\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1073.5298 - val_loss: 3840.4771\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 974.0782 - val_loss: 3569.1250\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 947.7079 - val_loss: 3255.0295\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 908.2631 - val_loss: 3219.3308\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 983.7596 - val_loss: 3587.0894\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1063.6317 - val_loss: 3445.8008\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1012.5957 - val_loss: 4959.8960\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1011.2737 - val_loss: 4107.7271\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 976.6039 - val_loss: 3329.3267\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1000.9001 - val_loss: 3522.9368\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 924.7492 - val_loss: 3764.5034\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 940.8048 - val_loss: 3215.8157\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 939.8370 - val_loss: 3804.6436\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 982.0089 - val_loss: 3409.6948\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 962.0204 - val_loss: 4224.2783\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 912.9290 - val_loss: 4502.9497\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 802.6262 - val_loss: 3792.0947\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 928.5980 - val_loss: 3584.3762\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 905.3528 - val_loss: 3805.5481\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 862.4476 - val_loss: 4020.3362\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 841.8367 - val_loss: 4105.5063\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 881.6474 - val_loss: 3725.4885\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 864.8051 - val_loss: 4158.2402\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 922.4293 - val_loss: 3477.0837\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 816.6347 - val_loss: 3397.5554\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 767.2029 - val_loss: 3387.5925\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 858.3956 - val_loss: 3513.4988\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 790.1671 - val_loss: 3906.6843\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 791.8649 - val_loss: 4674.2617\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 736.2236 - val_loss: 4052.3953\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 736.8849 - val_loss: 4343.1602\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 762.6816 - val_loss: 3525.2397\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 821.7994 - val_loss: 4043.6914\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 867.3915 - val_loss: 4165.9937\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 784.6204 - val_loss: 4786.1006\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 719.7629 - val_loss: 3821.9133\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 744.3941 - val_loss: 4821.4165\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 771.2014 - val_loss: 3799.7800\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 848.4493 - val_loss: 4169.9209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56e0739180>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, BatchNormalization, Dropout, Flatten, Dense\n",
    "\n",
    "# Load and preprocess data\n",
    "df = df\n",
    "df = df.set_index('Date')\n",
    "y = df.pop('AQI')\n",
    "y = y.values[30:]\n",
    "X = np.zeros((len(df) - 30, 30, 5))\n",
    "seq_length = 30\n",
    "\n",
    "for i in range(seq_length, len(df)):\n",
    "    X[i-seq_length] = df.values[i-seq_length:i]\n",
    "\n",
    "# Define model\n",
    "input_layer = Input(shape=(30, 5))\n",
    "conv1 = Conv1D(filters=64, kernel_size=2, activation='relu')(input_layer)\n",
    "max_pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "batch_norm1 = BatchNormalization()(max_pool1)\n",
    "conv2 = Conv1D(filters=64, kernel_size=2, activation='relu')(batch_norm1)\n",
    "max_pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "batch_norm2 = BatchNormalization()(max_pool2)\n",
    "flatten = Flatten()(batch_norm2)\n",
    "dense1 = Dense(32, activation='relu')(flatten)\n",
    "dropout = Dropout(0.2)(dense1)\n",
    "output_layer = Dense(1, activation='linear')(dropout)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
