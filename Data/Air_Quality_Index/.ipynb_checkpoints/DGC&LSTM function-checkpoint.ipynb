{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('AQI_finaldataset.csv')\n",
    "df = df.drop(['Location','CO','NO','NH3','O3'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>155</td>\n",
       "      <td>11.532500</td>\n",
       "      <td>14.119167</td>\n",
       "      <td>64.316667</td>\n",
       "      <td>71.244583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>175</td>\n",
       "      <td>17.677500</td>\n",
       "      <td>7.001667</td>\n",
       "      <td>101.994167</td>\n",
       "      <td>115.704583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>160</td>\n",
       "      <td>6.395833</td>\n",
       "      <td>3.274583</td>\n",
       "      <td>75.047500</td>\n",
       "      <td>81.250833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>160</td>\n",
       "      <td>9.455417</td>\n",
       "      <td>10.259167</td>\n",
       "      <td>74.220000</td>\n",
       "      <td>87.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>168</td>\n",
       "      <td>15.177917</td>\n",
       "      <td>6.458333</td>\n",
       "      <td>88.811250</td>\n",
       "      <td>98.957917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>157</td>\n",
       "      <td>24.267500</td>\n",
       "      <td>19.873750</td>\n",
       "      <td>68.129583</td>\n",
       "      <td>76.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>166</td>\n",
       "      <td>27.073750</td>\n",
       "      <td>14.355833</td>\n",
       "      <td>86.390000</td>\n",
       "      <td>99.132917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>143</td>\n",
       "      <td>3.838333</td>\n",
       "      <td>2.935000</td>\n",
       "      <td>52.775417</td>\n",
       "      <td>58.132917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>166</td>\n",
       "      <td>8.980833</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>85.993333</td>\n",
       "      <td>98.587083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>156</td>\n",
       "      <td>9.577500</td>\n",
       "      <td>3.736667</td>\n",
       "      <td>66.760833</td>\n",
       "      <td>74.665833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3695 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location_ID        Date  AQI        NO2        SO2       PM2.5  \\\n",
       "0               0  2020-01-12  155  11.532500  14.119167   64.316667   \n",
       "1               1  2020-01-12  175  17.677500   7.001667  101.994167   \n",
       "2               2  2020-01-12  160   6.395833   3.274583   75.047500   \n",
       "3               3  2020-01-12  160   9.455417  10.259167   74.220000   \n",
       "4               4  2020-01-12  168  15.177917   6.458333   88.811250   \n",
       "...           ...         ...  ...        ...        ...         ...   \n",
       "3690            0  2022-12-30  157  24.267500  19.873750   68.129583   \n",
       "3691            1  2022-12-30  166  27.073750  14.355833   86.390000   \n",
       "3692            2  2022-12-30  143   3.838333   2.935000   52.775417   \n",
       "3693            3  2022-12-30  166   8.980833  12.270000   85.993333   \n",
       "3694            4  2022-12-30  156   9.577500   3.736667   66.760833   \n",
       "\n",
       "            PM10  \n",
       "0      71.244583  \n",
       "1     115.704583  \n",
       "2      81.250833  \n",
       "3      87.468750  \n",
       "4      98.957917  \n",
       "...          ...  \n",
       "3690   76.675000  \n",
       "3691   99.132917  \n",
       "3692   58.132917  \n",
       "3693   98.587083  \n",
       "3694   74.665833  \n",
       "\n",
       "[3695 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on test data\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Calculate root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dgc_lstm_model(df, location_id):\n",
    "    # Filter data by location\n",
    "    df = df[df[\"Location_ID\"] == location_id]\n",
    "\n",
    "    # Convert date column to datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Sort data by date\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "    # Extract target variables\n",
    "    targets = [\"AQI\", \"NO2\", \"SO2\", \"PM10\", \"PM2.5\"]\n",
    "    y = df[targets]\n",
    "\n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "    # Define sequence length for LSTM\n",
    "    seq_length = 30\n",
    "\n",
    "    # Create input and output sequences\n",
    "    X, Y = [], []\n",
    "    for i in range(len(y_scaled) - seq_length):\n",
    "        X.append(y_scaled[i:i+seq_length])\n",
    "        Y.append(y_scaled[i+seq_length])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=(seq_length, len(targets)))\n",
    "\n",
    "    # Define spatial graph convolution layer\n",
    "    for i in range(3):\n",
    "        graph_conv = Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "        graph_conv = MaxPooling1D(pool_size=2)(graph_conv)\n",
    "        graph_conv = BatchNormalization()(graph_conv)\n",
    "\n",
    "        # Define temporal graph convolution layer\n",
    "        temp_conv = Conv1D(filters=64, kernel_size=2, activation='relu')(inputs)\n",
    "        temp_conv = MaxPooling1D(pool_size=2)(temp_conv)\n",
    "        temp_conv = BatchNormalization()(temp_conv)\n",
    "\n",
    "        # Concatenate graph convolutions\n",
    "        merged = Concatenate(axis=-1)([graph_conv, temp_conv])\n",
    "\n",
    "    # Define LSTM layer\n",
    "    lstm = LSTM(128)(merged)\n",
    "\n",
    "    # Define dense layers\n",
    "    dense = Dense(64, activation='relu')(lstm)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(len(targets))(dense)\n",
    "    dense = Dense(64, activation='relu')(lstm)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(len(targets))(dense)\n",
    "\n",
    "    # Define output layer\n",
    "    outputs = dense\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    # Train model\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), callbacks=[es], verbose=2)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/1885808831.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:30:01.848900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:30:02.177042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:30:02.269221: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 2s - loss: 0.0996 - val_loss: 0.0883 - 2s/epoch - 113ms/step\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:30:02.954121: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:30:03.037964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - loss: 0.0606 - val_loss: 0.0798 - 326ms/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0485 - val_loss: 0.0759 - 320ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0459 - val_loss: 0.0690 - 325ms/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0411 - val_loss: 0.0673 - 312ms/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0400 - val_loss: 0.0622 - 317ms/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0366 - val_loss: 0.0654 - 323ms/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0341 - val_loss: 0.0579 - 315ms/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0323 - val_loss: 0.0592 - 314ms/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0321 - val_loss: 0.0525 - 303ms/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0307 - val_loss: 0.0504 - 297ms/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0278 - val_loss: 0.0467 - 326ms/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0276 - val_loss: 0.0484 - 291ms/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0285 - val_loss: 0.0486 - 308ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0262 - val_loss: 0.0439 - 307ms/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0265 - val_loss: 0.0438 - 347ms/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0240 - val_loss: 0.0434 - 338ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0256 - val_loss: 0.0397 - 288ms/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0249 - val_loss: 0.0379 - 288ms/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0244 - val_loss: 0.0409 - 307ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0246 - val_loss: 0.0415 - 311ms/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0247 - val_loss: 0.0395 - 301ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0222 - val_loss: 0.0368 - 311ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0226 - val_loss: 0.0330 - 308ms/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0217 - val_loss: 0.0333 - 311ms/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0214 - val_loss: 0.0323 - 300ms/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0201 - val_loss: 0.0351 - 303ms/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0197 - val_loss: 0.0350 - 314ms/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0312 - 310ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0176 - val_loss: 0.0301 - 311ms/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0178 - val_loss: 0.0340 - 307ms/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0192 - val_loss: 0.0315 - 293ms/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0203 - val_loss: 0.0338 - 309ms/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0185 - val_loss: 0.0359 - 325ms/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0180 - val_loss: 0.0345 - 307ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0372 - 315ms/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0177 - val_loss: 0.0358 - 304ms/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0175 - val_loss: 0.0301 - 316ms/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0170 - val_loss: 0.0320 - 307ms/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0158 - val_loss: 0.0296 - 326ms/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0164 - val_loss: 0.0295 - 310ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0151 - val_loss: 0.0331 - 323ms/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0150 - val_loss: 0.0369 - 381ms/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0162 - val_loss: 0.0408 - 395ms/epoch - 22ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0152 - val_loss: 0.0402 - 308ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0358 - 299ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0343 - 301ms/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0142 - val_loss: 0.0318 - 341ms/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0331 - 301ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0147 - val_loss: 0.0326 - 302ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0131 - val_loss: 0.0297 - 287ms/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0141 - val_loss: 0.0298 - 332ms/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0140 - val_loss: 0.0261 - 316ms/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0271 - 305ms/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0273 - 302ms/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0139 - val_loss: 0.0297 - 297ms/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0309 - 304ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0134 - val_loss: 0.0377 - 297ms/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0416 - 294ms/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0133 - val_loss: 0.0375 - 297ms/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0408 - 293ms/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0338 - 306ms/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0334 - 300ms/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0129 - val_loss: 0.0301 - 325ms/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0300 - 333ms/epoch - 18ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0317 - 309ms/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0307 - 301ms/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "18/18 - 0s - loss: 0.0115 - val_loss: 0.0292 - 304ms/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0258 - 307ms/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "18/18 - 0s - loss: 0.0117 - val_loss: 0.0271 - 316ms/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0260 - 335ms/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0295 - 298ms/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0277 - 305ms/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0279 - 308ms/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "18/18 - 0s - loss: 0.0115 - val_loss: 0.0281 - 330ms/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0307 - 316ms/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "18/18 - 0s - loss: 0.0108 - val_loss: 0.0274 - 310ms/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "18/18 - 0s - loss: 0.0106 - val_loss: 0.0262 - 338ms/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0283 - 321ms/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0310 - 315ms/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0254 - 320ms/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0253 - 320ms/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0267 - 325ms/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0257 - 302ms/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "18/18 - 0s - loss: 0.0113 - val_loss: 0.0251 - 300ms/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "18/18 - 0s - loss: 0.0109 - val_loss: 0.0275 - 294ms/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0285 - 325ms/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0275 - 308ms/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "18/18 - 0s - loss: 0.0099 - val_loss: 0.0256 - 306ms/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0273 - 314ms/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "18/18 - 0s - loss: 0.0111 - val_loss: 0.0289 - 308ms/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "18/18 - 0s - loss: 0.0110 - val_loss: 0.0252 - 322ms/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0293 - 314ms/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "18/18 - 0s - loss: 0.0101 - val_loss: 0.0272 - 333ms/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "18/18 - 0s - loss: 0.0097 - val_loss: 0.0275 - 327ms/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "18/18 - 0s - loss: 0.0093 - val_loss: 0.0269 - 335ms/epoch - 19ms/step\n",
      "Epoch 97/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0277 - 316ms/epoch - 18ms/step\n",
      "Epoch 98/100\n",
      "18/18 - 0s - loss: 0.0102 - val_loss: 0.0265 - 313ms/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "18/18 - 0s - loss: 0.0094 - val_loss: 0.0269 - 309ms/epoch - 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "18/18 - 0s - loss: 0.0093 - val_loss: 0.0279 - 309ms/epoch - 17ms/step\n"
     ]
    }
   ],
   "source": [
    "model_a1 = train_dgc_lstm_model(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, X_test, scaler, seq_length, targets, start_date, end_date, freq='D'):\n",
    "    \"\"\"\n",
    "    Generates predictions for future dates using a trained LSTM model.\n",
    "\n",
    "    Args:\n",
    "    - model: a trained Keras LSTM model\n",
    "    - X_test: a numpy array of shape (num_samples, seq_length, num_features) containing test data\n",
    "    - scaler: a fitted sklearn.preprocessing.MinMaxScaler object used to scale the data\n",
    "    - seq_length: the sequence length used for training the model\n",
    "    - targets: a list of target column names\n",
    "    - start_date: the start date for the future date range (string in 'YYYY-MM-DD' format)\n",
    "    - end_date: the end date for the future date range (string in 'YYYY-MM-DD' format)\n",
    "    - freq: the frequency of the future date range (default='D')\n",
    "\n",
    "    Returns:\n",
    "    - preds_df: a pandas DataFrame of shape (num_predictions, num_targets) containing the predicted values\n",
    "    \"\"\"\n",
    "    # Define future date range\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "\n",
    "    # Create input sequences for future dates\n",
    "    last_seq = np.array(X_test[-1])  # last sequence from the test data\n",
    "    input_seq = last_seq.copy()\n",
    "    preds = []\n",
    "    for i in range(len(future_dates)):\n",
    "        pred = model.predict(input_seq.reshape(1, seq_length, len(targets)))\n",
    "        preds.append(pred)\n",
    "        input_seq = np.append(input_seq[1:], pred, axis=0)\n",
    "\n",
    "    # Inverse transform the predicted values\n",
    "    preds = np.array(preds).reshape(-1, len(targets))\n",
    "    preds_inv = scaler.inverse_transform(preds)\n",
    "\n",
    "    # Convert predictions and dates to a pandas DataFrame\n",
    "    preds_df = pd.DataFrame(preds_inv, index=future_dates, columns=targets)\n",
    "\n",
    "    return preds_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:31:07.794324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:31:07.898232: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>162.523788</td>\n",
       "      <td>11.167418</td>\n",
       "      <td>14.255235</td>\n",
       "      <td>93.550308</td>\n",
       "      <td>81.979271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-02</th>\n",
       "      <td>148.921844</td>\n",
       "      <td>9.537496</td>\n",
       "      <td>12.976024</td>\n",
       "      <td>84.865593</td>\n",
       "      <td>74.539513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03</th>\n",
       "      <td>152.632736</td>\n",
       "      <td>9.872520</td>\n",
       "      <td>11.704534</td>\n",
       "      <td>82.854492</td>\n",
       "      <td>71.401192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-04</th>\n",
       "      <td>180.298477</td>\n",
       "      <td>11.798573</td>\n",
       "      <td>14.726301</td>\n",
       "      <td>106.969116</td>\n",
       "      <td>93.979752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-05</th>\n",
       "      <td>170.798859</td>\n",
       "      <td>11.148227</td>\n",
       "      <td>13.152823</td>\n",
       "      <td>101.216438</td>\n",
       "      <td>88.853577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06</th>\n",
       "      <td>152.787964</td>\n",
       "      <td>11.065556</td>\n",
       "      <td>13.720207</td>\n",
       "      <td>90.383537</td>\n",
       "      <td>80.171448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>162.080917</td>\n",
       "      <td>10.013520</td>\n",
       "      <td>13.988982</td>\n",
       "      <td>91.313484</td>\n",
       "      <td>80.437233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>186.766342</td>\n",
       "      <td>10.476390</td>\n",
       "      <td>16.331343</td>\n",
       "      <td>108.023811</td>\n",
       "      <td>94.844765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>180.666489</td>\n",
       "      <td>10.571139</td>\n",
       "      <td>15.781747</td>\n",
       "      <td>102.292770</td>\n",
       "      <td>89.433189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>170.329193</td>\n",
       "      <td>10.640274</td>\n",
       "      <td>15.417902</td>\n",
       "      <td>97.506882</td>\n",
       "      <td>85.453720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-11</th>\n",
       "      <td>167.879532</td>\n",
       "      <td>9.710434</td>\n",
       "      <td>14.502666</td>\n",
       "      <td>92.298775</td>\n",
       "      <td>80.296844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-12</th>\n",
       "      <td>189.620697</td>\n",
       "      <td>10.767115</td>\n",
       "      <td>16.049006</td>\n",
       "      <td>108.547554</td>\n",
       "      <td>94.347214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>184.512314</td>\n",
       "      <td>10.541819</td>\n",
       "      <td>14.618626</td>\n",
       "      <td>103.246925</td>\n",
       "      <td>89.315735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14</th>\n",
       "      <td>159.222992</td>\n",
       "      <td>9.942591</td>\n",
       "      <td>13.165209</td>\n",
       "      <td>86.114487</td>\n",
       "      <td>74.071663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15</th>\n",
       "      <td>160.245148</td>\n",
       "      <td>9.620550</td>\n",
       "      <td>12.606546</td>\n",
       "      <td>84.550453</td>\n",
       "      <td>72.154495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-16</th>\n",
       "      <td>175.514313</td>\n",
       "      <td>10.174840</td>\n",
       "      <td>13.843532</td>\n",
       "      <td>95.806602</td>\n",
       "      <td>81.809868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17</th>\n",
       "      <td>169.855652</td>\n",
       "      <td>10.171059</td>\n",
       "      <td>13.030133</td>\n",
       "      <td>94.043701</td>\n",
       "      <td>80.956810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-18</th>\n",
       "      <td>164.922653</td>\n",
       "      <td>10.676130</td>\n",
       "      <td>12.863521</td>\n",
       "      <td>95.639496</td>\n",
       "      <td>83.027382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-19</th>\n",
       "      <td>171.853012</td>\n",
       "      <td>10.952326</td>\n",
       "      <td>13.778387</td>\n",
       "      <td>99.275780</td>\n",
       "      <td>85.688560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-20</th>\n",
       "      <td>182.864395</td>\n",
       "      <td>11.161283</td>\n",
       "      <td>14.687943</td>\n",
       "      <td>106.206924</td>\n",
       "      <td>91.505981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-21</th>\n",
       "      <td>177.064270</td>\n",
       "      <td>10.600306</td>\n",
       "      <td>14.002193</td>\n",
       "      <td>99.539391</td>\n",
       "      <td>85.243095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-22</th>\n",
       "      <td>175.897263</td>\n",
       "      <td>10.351958</td>\n",
       "      <td>14.269053</td>\n",
       "      <td>97.879936</td>\n",
       "      <td>83.587021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-23</th>\n",
       "      <td>167.907394</td>\n",
       "      <td>9.656161</td>\n",
       "      <td>13.686399</td>\n",
       "      <td>89.574730</td>\n",
       "      <td>76.083832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24</th>\n",
       "      <td>181.463470</td>\n",
       "      <td>10.678943</td>\n",
       "      <td>15.068107</td>\n",
       "      <td>99.990929</td>\n",
       "      <td>84.949570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-25</th>\n",
       "      <td>176.721085</td>\n",
       "      <td>10.649586</td>\n",
       "      <td>14.494112</td>\n",
       "      <td>97.915077</td>\n",
       "      <td>83.547508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26</th>\n",
       "      <td>165.182388</td>\n",
       "      <td>10.422557</td>\n",
       "      <td>13.653762</td>\n",
       "      <td>91.293198</td>\n",
       "      <td>78.074127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27</th>\n",
       "      <td>167.960297</td>\n",
       "      <td>10.204235</td>\n",
       "      <td>13.328257</td>\n",
       "      <td>91.826416</td>\n",
       "      <td>78.315033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>179.255859</td>\n",
       "      <td>10.609464</td>\n",
       "      <td>14.142268</td>\n",
       "      <td>100.585869</td>\n",
       "      <td>86.052765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AQI        NO2        SO2        PM10      PM2.5\n",
       "2023-02-01  162.523788  11.167418  14.255235   93.550308  81.979271\n",
       "2023-02-02  148.921844   9.537496  12.976024   84.865593  74.539513\n",
       "2023-02-03  152.632736   9.872520  11.704534   82.854492  71.401192\n",
       "2023-02-04  180.298477  11.798573  14.726301  106.969116  93.979752\n",
       "2023-02-05  170.798859  11.148227  13.152823  101.216438  88.853577\n",
       "2023-02-06  152.787964  11.065556  13.720207   90.383537  80.171448\n",
       "2023-02-07  162.080917  10.013520  13.988982   91.313484  80.437233\n",
       "2023-02-08  186.766342  10.476390  16.331343  108.023811  94.844765\n",
       "2023-02-09  180.666489  10.571139  15.781747  102.292770  89.433189\n",
       "2023-02-10  170.329193  10.640274  15.417902   97.506882  85.453720\n",
       "2023-02-11  167.879532   9.710434  14.502666   92.298775  80.296844\n",
       "2023-02-12  189.620697  10.767115  16.049006  108.547554  94.347214\n",
       "2023-02-13  184.512314  10.541819  14.618626  103.246925  89.315735\n",
       "2023-02-14  159.222992   9.942591  13.165209   86.114487  74.071663\n",
       "2023-02-15  160.245148   9.620550  12.606546   84.550453  72.154495\n",
       "2023-02-16  175.514313  10.174840  13.843532   95.806602  81.809868\n",
       "2023-02-17  169.855652  10.171059  13.030133   94.043701  80.956810\n",
       "2023-02-18  164.922653  10.676130  12.863521   95.639496  83.027382\n",
       "2023-02-19  171.853012  10.952326  13.778387   99.275780  85.688560\n",
       "2023-02-20  182.864395  11.161283  14.687943  106.206924  91.505981\n",
       "2023-02-21  177.064270  10.600306  14.002193   99.539391  85.243095\n",
       "2023-02-22  175.897263  10.351958  14.269053   97.879936  83.587021\n",
       "2023-02-23  167.907394   9.656161  13.686399   89.574730  76.083832\n",
       "2023-02-24  181.463470  10.678943  15.068107   99.990929  84.949570\n",
       "2023-02-25  176.721085  10.649586  14.494112   97.915077  83.547508\n",
       "2023-02-26  165.182388  10.422557  13.653762   91.293198  78.074127\n",
       "2023-02-27  167.960297  10.204235  13.328257   91.826416  78.315033\n",
       "2023-02-28  179.255859  10.609464  14.142268  100.585869  86.052765"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_future(model_a1, X_test, scaler, seq_length, targets, start_date='2023-02-01', end_date='2023-02-28', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/7vt__1z91mb3zslygkxndqpw0000gn/T/ipykernel_68188/1885808831.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
      "/Users/aman/tensorflow-test/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:37:04.509641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.010126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.104594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.884573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:05.974438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 2s - loss: 0.0871 - val_loss: 0.0569 - 2s/epoch - 135ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 0.0501 - val_loss: 0.0503 - 340ms/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 0.0384 - val_loss: 0.0487 - 324ms/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 0.0351 - val_loss: 0.0441 - 312ms/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 0.0340 - val_loss: 0.0455 - 327ms/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 0.0322 - val_loss: 0.0519 - 303ms/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 0.0305 - val_loss: 0.0452 - 325ms/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 0.0286 - val_loss: 0.0471 - 343ms/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 0.0267 - val_loss: 0.0431 - 334ms/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 0.0257 - val_loss: 0.0403 - 327ms/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 0.0231 - val_loss: 0.0396 - 300ms/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 0.0232 - val_loss: 0.0418 - 338ms/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 0.0239 - val_loss: 0.0407 - 299ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 0.0212 - val_loss: 0.0371 - 306ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 0.0211 - val_loss: 0.0371 - 301ms/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 0.0217 - val_loss: 0.0346 - 326ms/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 0.0207 - val_loss: 0.0323 - 333ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 0.0196 - val_loss: 0.0374 - 337ms/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 0.0191 - val_loss: 0.0358 - 316ms/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 0.0168 - val_loss: 0.0327 - 309ms/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 0.0172 - val_loss: 0.0344 - 339ms/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 0.0167 - val_loss: 0.0317 - 325ms/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 0.0175 - val_loss: 0.0307 - 302ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 0.0172 - val_loss: 0.0310 - 317ms/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 0.0155 - val_loss: 0.0275 - 303ms/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 0.0159 - val_loss: 0.0272 - 305ms/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 0.0160 - val_loss: 0.0268 - 296ms/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 0.0159 - val_loss: 0.0274 - 315ms/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 0.0154 - val_loss: 0.0249 - 298ms/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 0.0155 - val_loss: 0.0254 - 291ms/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 0.0143 - val_loss: 0.0277 - 324ms/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 0.0149 - val_loss: 0.0251 - 297ms/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0240 - 313ms/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0252 - 312ms/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 0.0138 - val_loss: 0.0271 - 302ms/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 0.0136 - val_loss: 0.0288 - 297ms/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 0.0137 - val_loss: 0.0245 - 296ms/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0242 - 327ms/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 0.0144 - val_loss: 0.0237 - 292ms/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 0.0132 - val_loss: 0.0268 - 298ms/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 0.0127 - val_loss: 0.0323 - 310ms/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 0.0122 - val_loss: 0.0247 - 306ms/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0296 - 325ms/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 0.0133 - val_loss: 0.0233 - 323ms/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 0.0130 - val_loss: 0.0222 - 310ms/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0226 - 306ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 0.0114 - val_loss: 0.0249 - 339ms/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 0.0125 - val_loss: 0.0223 - 283ms/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 0.0122 - val_loss: 0.0244 - 315ms/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 0.0120 - val_loss: 0.0248 - 341ms/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 0.0124 - val_loss: 0.0274 - 306ms/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0238 - 291ms/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 0.0118 - val_loss: 0.0239 - 327ms/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 0.0121 - val_loss: 0.0245 - 335ms/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 0.0128 - val_loss: 0.0260 - 329ms/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 0.0111 - val_loss: 0.0248 - 303ms/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0252 - 315ms/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0245 - 320ms/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 0.0119 - val_loss: 0.0235 - 330ms/epoch - 18ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 0.0116 - val_loss: 0.0234 - 304ms/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 0.0104 - val_loss: 0.0240 - 292ms/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 0.0105 - val_loss: 0.0264 - 313ms/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 0.0112 - val_loss: 0.0253 - 346ms/epoch - 19ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 0.0103 - val_loss: 0.0243 - 304ms/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 0.0095 - val_loss: 0.0253 - 351ms/epoch - 19ms/step\n",
      "Epoch 65: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_a0 = train_dgc_lstm_model(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:37:50.462930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-20 18:37:50.596795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>162.771133</td>\n",
       "      <td>8.578809</td>\n",
       "      <td>10.257969</td>\n",
       "      <td>74.333763</td>\n",
       "      <td>65.543640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-02</th>\n",
       "      <td>155.618668</td>\n",
       "      <td>9.642659</td>\n",
       "      <td>10.749367</td>\n",
       "      <td>65.164429</td>\n",
       "      <td>58.346062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03</th>\n",
       "      <td>137.193817</td>\n",
       "      <td>10.482187</td>\n",
       "      <td>10.591032</td>\n",
       "      <td>66.760521</td>\n",
       "      <td>60.936653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-04</th>\n",
       "      <td>148.329849</td>\n",
       "      <td>9.368301</td>\n",
       "      <td>9.232942</td>\n",
       "      <td>65.932884</td>\n",
       "      <td>56.474411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-05</th>\n",
       "      <td>162.153366</td>\n",
       "      <td>12.445340</td>\n",
       "      <td>13.331022</td>\n",
       "      <td>84.649017</td>\n",
       "      <td>74.881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06</th>\n",
       "      <td>165.553268</td>\n",
       "      <td>11.889607</td>\n",
       "      <td>12.774716</td>\n",
       "      <td>86.200409</td>\n",
       "      <td>75.430260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>181.898666</td>\n",
       "      <td>13.350243</td>\n",
       "      <td>15.209957</td>\n",
       "      <td>104.040871</td>\n",
       "      <td>91.545937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>191.209564</td>\n",
       "      <td>10.657102</td>\n",
       "      <td>12.977812</td>\n",
       "      <td>97.556847</td>\n",
       "      <td>81.120544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>198.160217</td>\n",
       "      <td>11.220460</td>\n",
       "      <td>13.994368</td>\n",
       "      <td>98.291000</td>\n",
       "      <td>81.231293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>196.761093</td>\n",
       "      <td>9.032623</td>\n",
       "      <td>11.634832</td>\n",
       "      <td>88.886742</td>\n",
       "      <td>69.486313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-11</th>\n",
       "      <td>208.225677</td>\n",
       "      <td>10.490720</td>\n",
       "      <td>13.548796</td>\n",
       "      <td>99.889824</td>\n",
       "      <td>79.141953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-12</th>\n",
       "      <td>190.273300</td>\n",
       "      <td>9.291825</td>\n",
       "      <td>11.432539</td>\n",
       "      <td>87.235283</td>\n",
       "      <td>65.229828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>186.621338</td>\n",
       "      <td>11.175428</td>\n",
       "      <td>13.070667</td>\n",
       "      <td>93.143364</td>\n",
       "      <td>73.343445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14</th>\n",
       "      <td>178.882721</td>\n",
       "      <td>10.152822</td>\n",
       "      <td>11.581899</td>\n",
       "      <td>84.456848</td>\n",
       "      <td>63.832241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15</th>\n",
       "      <td>187.000977</td>\n",
       "      <td>10.362572</td>\n",
       "      <td>12.143617</td>\n",
       "      <td>89.924461</td>\n",
       "      <td>68.058578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-16</th>\n",
       "      <td>184.692215</td>\n",
       "      <td>10.710979</td>\n",
       "      <td>12.256781</td>\n",
       "      <td>88.811188</td>\n",
       "      <td>67.511047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17</th>\n",
       "      <td>185.523697</td>\n",
       "      <td>10.271967</td>\n",
       "      <td>11.966063</td>\n",
       "      <td>89.990372</td>\n",
       "      <td>67.723412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-18</th>\n",
       "      <td>182.993393</td>\n",
       "      <td>10.392121</td>\n",
       "      <td>12.004256</td>\n",
       "      <td>90.311455</td>\n",
       "      <td>68.707077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-19</th>\n",
       "      <td>194.465134</td>\n",
       "      <td>10.559232</td>\n",
       "      <td>12.738009</td>\n",
       "      <td>96.866722</td>\n",
       "      <td>73.668747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-20</th>\n",
       "      <td>193.575378</td>\n",
       "      <td>10.294939</td>\n",
       "      <td>12.468082</td>\n",
       "      <td>96.060532</td>\n",
       "      <td>72.832115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-21</th>\n",
       "      <td>199.844116</td>\n",
       "      <td>10.297045</td>\n",
       "      <td>12.825958</td>\n",
       "      <td>98.022995</td>\n",
       "      <td>73.986191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-22</th>\n",
       "      <td>198.680237</td>\n",
       "      <td>9.486366</td>\n",
       "      <td>11.961335</td>\n",
       "      <td>94.081612</td>\n",
       "      <td>69.578209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-23</th>\n",
       "      <td>201.805771</td>\n",
       "      <td>9.920100</td>\n",
       "      <td>12.433014</td>\n",
       "      <td>95.374207</td>\n",
       "      <td>70.369370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24</th>\n",
       "      <td>192.146805</td>\n",
       "      <td>9.126615</td>\n",
       "      <td>11.425615</td>\n",
       "      <td>88.791389</td>\n",
       "      <td>64.561165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-25</th>\n",
       "      <td>191.242950</td>\n",
       "      <td>9.591578</td>\n",
       "      <td>11.804286</td>\n",
       "      <td>89.208031</td>\n",
       "      <td>65.571892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26</th>\n",
       "      <td>187.911926</td>\n",
       "      <td>9.166576</td>\n",
       "      <td>11.331486</td>\n",
       "      <td>86.675568</td>\n",
       "      <td>63.201927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27</th>\n",
       "      <td>186.261963</td>\n",
       "      <td>9.053236</td>\n",
       "      <td>11.142272</td>\n",
       "      <td>85.812317</td>\n",
       "      <td>62.713703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>186.022430</td>\n",
       "      <td>9.608478</td>\n",
       "      <td>11.679623</td>\n",
       "      <td>88.501999</td>\n",
       "      <td>65.765137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AQI        NO2        SO2        PM10      PM2.5\n",
       "2023-02-01  162.771133   8.578809  10.257969   74.333763  65.543640\n",
       "2023-02-02  155.618668   9.642659  10.749367   65.164429  58.346062\n",
       "2023-02-03  137.193817  10.482187  10.591032   66.760521  60.936653\n",
       "2023-02-04  148.329849   9.368301   9.232942   65.932884  56.474411\n",
       "2023-02-05  162.153366  12.445340  13.331022   84.649017  74.881264\n",
       "2023-02-06  165.553268  11.889607  12.774716   86.200409  75.430260\n",
       "2023-02-07  181.898666  13.350243  15.209957  104.040871  91.545937\n",
       "2023-02-08  191.209564  10.657102  12.977812   97.556847  81.120544\n",
       "2023-02-09  198.160217  11.220460  13.994368   98.291000  81.231293\n",
       "2023-02-10  196.761093   9.032623  11.634832   88.886742  69.486313\n",
       "2023-02-11  208.225677  10.490720  13.548796   99.889824  79.141953\n",
       "2023-02-12  190.273300   9.291825  11.432539   87.235283  65.229828\n",
       "2023-02-13  186.621338  11.175428  13.070667   93.143364  73.343445\n",
       "2023-02-14  178.882721  10.152822  11.581899   84.456848  63.832241\n",
       "2023-02-15  187.000977  10.362572  12.143617   89.924461  68.058578\n",
       "2023-02-16  184.692215  10.710979  12.256781   88.811188  67.511047\n",
       "2023-02-17  185.523697  10.271967  11.966063   89.990372  67.723412\n",
       "2023-02-18  182.993393  10.392121  12.004256   90.311455  68.707077\n",
       "2023-02-19  194.465134  10.559232  12.738009   96.866722  73.668747\n",
       "2023-02-20  193.575378  10.294939  12.468082   96.060532  72.832115\n",
       "2023-02-21  199.844116  10.297045  12.825958   98.022995  73.986191\n",
       "2023-02-22  198.680237   9.486366  11.961335   94.081612  69.578209\n",
       "2023-02-23  201.805771   9.920100  12.433014   95.374207  70.369370\n",
       "2023-02-24  192.146805   9.126615  11.425615   88.791389  64.561165\n",
       "2023-02-25  191.242950   9.591578  11.804286   89.208031  65.571892\n",
       "2023-02-26  187.911926   9.166576  11.331486   86.675568  63.201927\n",
       "2023-02-27  186.261963   9.053236  11.142272   85.812317  62.713703\n",
       "2023-02-28  186.022430   9.608478  11.679623   88.501999  65.765137"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_future(model_a0, X_test, scaler, seq_length, targets, start_date='2023-02-01', end_date='2023-02-28', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_map = {'Adilabad': 0, \n",
    "                'Karimnagar': 1, \n",
    "                'Khammam': 2, \n",
    "                'Nizamabad': 3, \n",
    "                'Warangal': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_Adilabad 0\n",
      "model_Karimnagar 1\n",
      "model_Khammam 2\n",
      "model_Nizamabad 3\n",
      "model_Warangal 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
